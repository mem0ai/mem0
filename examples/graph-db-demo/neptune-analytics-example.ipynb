{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune as Graph Memory\n",
    "\n",
    "In this notebook, we will be connecting using a Amazon Neptune Analytics instance as our memory graph storage for Mem0.\n",
    "\n",
    "The Graph Memory storage persists memories in a graph or relationship form when performing `m.add` memory operations. It then uses vector distance algorithms to find related memories during a `m.search` operation. Relationships are returned in the result, and add context to the memories.\n",
    "\n",
    "Reference: [Vector Similarity using Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/vector-similarity.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### 1. Install Mem0 with Graph Memory support \n",
    "\n",
    "To use Mem0 with Graph Memory support (as well as other Amazon services), use pip install:\n",
    "\n",
    "```bash\n",
    "pip install \"mem0ai[graph,extras]\"\n",
    "```\n",
    "\n",
    "This command installs Mem0 along with the necessary dependencies for graph functionality (`graph`) and other Amazon dependencies (`extras`).\n",
    "\n",
    "### 2. Connect to Amazon services\n",
    "\n",
    "For this sample notebook, configure `mem0ai` with [Amazon Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html) as the graph store, [Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-overview.html) as the vector store, and [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html) for generating embeddings.\n",
    "\n",
    "Use the following guide for setup details: [Setup AWS Bedrock, AOSS, and Neptune](https://docs.mem0.ai/examples/aws_example#aws-bedrock-and-aoss)\n",
    "\n",
    "Your configuration should look similar to:\n",
    "\n",
    "```python\n",
    "config = {\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"aws_bedrock\",\n",
    "        \"config\": {\n",
    "            \"model\": \"amazon.titan-embed-text-v2:0\"\n",
    "        }\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"aws_bedrock\",\n",
    "        \"config\": {\n",
    "            \"model\": \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "    },\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"opensearch\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"mem0\",\n",
    "            \"host\": \"your-opensearch-domain.us-west-2.es.amazonaws.com\",\n",
    "            \"port\": 443,\n",
    "            \"http_auth\": auth,\n",
    "            \"connection_class\": RequestsHttpConnection,\n",
    "            \"pool_maxsize\": 20,\n",
    "            \"use_ssl\": True,\n",
    "            \"verify_certs\": True,\n",
    "            \"embedding_model_dims\": 1024,\n",
    "        }\n",
    "    },\n",
    "    \"graph_store\": {\n",
    "        \"provider\": \"neptune\",\n",
    "        \"config\": {\n",
    "            \"endpoint\": f\"neptune-graph://my-graph-identifier\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import all packages and setup logging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:39:13.059725Z",
     "start_time": "2025-08-19T16:39:11.886694Z"
    }
   },
   "source": [
    "from mem0 import Memory\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import boto3\n",
    "from opensearchpy import RequestsHttpConnection, AWSV4SignerAuth\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.getLogger(\"mem0.graphs.neptune.neptunegraph\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"mem0.graphs.neptune.base\").setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    stream=sys.stdout,  # Explicitly set output to stdout\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Mem0 configuration using:\n",
    "- Amazon Bedrock as the embedder\n",
    "- Amazon Neptune Analytics instance as a graph store\n",
    "- OpenSearch as the vector store"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:39:13.799647Z",
     "start_time": "2025-08-19T16:39:13.778446Z"
    }
   },
   "source": [
    "bedrock_embedder_model = \"amazon.titan-embed-text-v2:0\"\n",
    "bedrock_llm_model = \"anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "embedding_model_dims = 1025\n",
    "\n",
    "embedding_model_dims = 1536\n",
    "\n",
    "graph_identifier = os.environ.get(\"GRAPH_ID\")\n",
    "\n",
    "opensearch_host = os.environ.get(\"OS_HOST\")\n",
    "opensearch_port = 443\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "region = os.environ.get(\"AWS_REGION\")\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "\n",
    "config = {\n",
    "    # \"embedder\": {\n",
    "    #     \"provider\": \"aws_bedrock\",\n",
    "    #     \"config\": {\n",
    "    #         \"model\": bedrock_embedder_model,\n",
    "    #     }\n",
    "    # },\n",
    "    # \"llm\": {\n",
    "    #     \"provider\": \"aws_bedrock\",\n",
    "    #     \"config\": {\n",
    "    #         \"model\": bedrock_llm_model,\n",
    "    #         \"temperature\": 0.1,\n",
    "    #         \"max_tokens\": 2000\n",
    "    #     }\n",
    "    # },\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"opensearch\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"mem0ai_vector_store\",\n",
    "            \"host\": opensearch_host,\n",
    "            \"port\": opensearch_port,\n",
    "            \"http_auth\": auth,\n",
    "            \"embedding_model_dims\": embedding_model_dims,\n",
    "            \"use_ssl\": True,\n",
    "            \"verify_certs\": True,\n",
    "            \"connection_class\": RequestsHttpConnection,\n",
    "        },\n",
    "    },\n",
    "    \"graph_store\": {\n",
    "        \"provider\": \"neptune\",\n",
    "        \"config\": {\n",
    "            \"endpoint\": f\"neptune-graph://{graph_identifier}\",\n",
    "        },\n",
    "    },\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Memory initializiation\n",
    "\n",
    "Initialize Memgraph as a Graph Memory store:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:39:27.529189Z",
     "start_time": "2025-08-19T16:39:23.894468Z"
    }
   },
   "source": [
    "m = Memory.from_config(config_dict=config)\n",
    "\n",
    "app_id = \"movies\"\n",
    "user_id = \"alice\"\n",
    "\n",
    "m.delete_all(user_id=user_id)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - Configuration validation error: 3 validation errors for MemoryConfig\n",
      "graph_store.config.Neo4jConfig\n",
      "  Value error, Please provide 'url', 'username' and 'password'. [type=value_error, input_value={'endpoint': 'neptune-graph://g-11yqoe2pba'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/value_error\n",
      "graph_store.config.MemgraphConfig\n",
      "  Value error, Please provide 'url', 'username' and 'password'. [type=value_error, input_value={'endpoint': 'neptune-graph://g-11yqoe2pba'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/value_error\n",
      "graph_store.config.NeptuneConfig\n",
      "  Input should be a valid dictionary or instance of NeptuneConfig [type=model_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewc/Library/Application Support/JetBrains/IntelliJIdea2025.1/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_collect_try_except_info.py:153: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  if not hasattr(co, 'co_lnotab'):\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for MemoryConfig\ngraph_store.config.Neo4jConfig\n  Value error, Please provide 'url', 'username' and 'password'. [type=value_error, input_value={'endpoint': 'neptune-graph://g-11yqoe2pba'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error\ngraph_store.config.MemgraphConfig\n  Value error, Please provide 'url', 'username' and 'password'. [type=value_error, input_value={'endpoint': 'neptune-graph://g-11yqoe2pba'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error\ngraph_store.config.NeptuneConfig\n  Input should be a valid dictionary or instance of NeptuneConfig [type=model_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValidationError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m m = \u001B[43mMemory\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m app_id = \u001B[33m\"\u001B[39m\u001B[33mmovies\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      4\u001B[39m user_id = \u001B[33m\"\u001B[39m\u001B[33malice\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/mem0/memory/main.py:163\u001B[39m, in \u001B[36mMemory.from_config\u001B[39m\u001B[34m(cls, config_dict)\u001B[39m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    162\u001B[39m     config = \u001B[38;5;28mcls\u001B[39m._process_config(config_dict)\n\u001B[32m--> \u001B[39m\u001B[32m163\u001B[39m     config = \u001B[43mMemoryConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mconfig_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    165\u001B[39m     logger.error(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mConfiguration validation error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001B[39m, in \u001B[36mBaseModel.__init__\u001B[39m\u001B[34m(self, **data)\u001B[39m\n\u001B[32m    251\u001B[39m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[32m    252\u001B[39m __tracebackhide__ = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m253\u001B[39m validated_self = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[32m    255\u001B[39m     warnings.warn(\n\u001B[32m    256\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m\n\u001B[32m    257\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    258\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m    259\u001B[39m         stacklevel=\u001B[32m2\u001B[39m,\n\u001B[32m    260\u001B[39m     )\n",
      "\u001B[31mValidationError\u001B[39m: 3 validation errors for MemoryConfig\ngraph_store.config.Neo4jConfig\n  Value error, Please provide 'url', 'username' and 'password'. [type=value_error, input_value={'endpoint': 'neptune-graph://g-11yqoe2pba'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error\ngraph_store.config.MemgraphConfig\n  Value error, Please provide 'url', 'username' and 'password'. [type=value_error, input_value={'endpoint': 'neptune-graph://g-11yqoe2pba'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error\ngraph_store.config.NeptuneConfig\n  Input should be a valid dictionary or instance of NeptuneConfig [type=model_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store memories\n",
    "\n",
    "Create memories and store one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Explorer Visualization\n",
    "\n",
    "You can visualize the graph using a Graph Explorer connection to Neptune Analytics in Neptune Notebooks in the Amazon console.  See [Using Amazon Neptune with graph notebooks](https://docs.aws.amazon.com/neptune/latest/userguide/graph-notebooks.html) for instructions on how to setup a Neptune Notebook with Graph Explorer.\n",
    "\n",
    "Once the graph has been generated, you can open the visualization in the Neptune > Notebooks and click on Actions > Open Graph Explorer.  This will automatically connect to your neptune analytics graph that was provided in the notebook setup.\n",
    "\n",
    "Once in Graph Explorer, visit Open Connections and send all the available nodes and edges to Explorer. Visit Open Graph Explorer to see the nodes and edges in the graph.\n",
    "\n",
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-1.png](./neptune-example-visualization-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"How about a thriller movies? They can be quite engaging.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "\"thriller\" --type_of--> \"movie\"\n",
    "\"movie\" --can_be--> \"engaging\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-2.png](./neptune-example-visualization-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm not a big fan of thriller movies but I love sci-fi movies.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --dislikes--> \"thriller_movies\"\n",
    "\"alice\" --loves--> \"sci-fi_movies\"\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "\"thriller\" --type_of--> \"movie\"\n",
    "\"movie\" --can_be--> \"engaging\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-3.png](./neptune-example-visualization-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --recommends--> \"sci-fi\"\n",
    "\"alice\" --dislikes--> \"thriller_movies\"\n",
    "\"alice\" --loves--> \"sci-fi_movies\"\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "\"alice\" --avoids--> \"thriller\"\n",
    "\"thriller\" --type_of--> \"movie\"\n",
    "\"movie\" --can_be--> \"engaging\"\n",
    "\"sci-fi\" --type_of--> \"movie\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-4.png](./neptune-example-visualization-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search memories\n",
    "\n",
    "Search all memories for \"what does alice love?\".  Since \"alice\" the user, this will search for a relationship that fits the users love of \"sci-fi\" movies and dislike of \"thriller\" movies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "search_results = m.search(\"what does alice love?\", user_id=user_id)\n",
    "for result in search_results[\"results\"]:\n",
    "    print(f\"\\\"{result['memory']}\\\" [score: {result['score']}]\")\n",
    "for relation in search_results[\"relations\"]:\n",
    "    print(f\"{relation}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "m.delete_all(user_id)\n",
    "m.reset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this example we demonstrated how an AWS tech stack can be used to store and retrieve memory context. Bedrock LLM models can be used to interpret given conversations.  OpenSearch can store text chunks with vector embeddings. Neptune Analytics can store the text chunks in a graph format with relationship entities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
