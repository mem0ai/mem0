{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using **mem0** with Azure resources and Azure Identity credentials\n",
    "\n",
    "This example demonstrates how to utilize **mem0** with Azure Identity credentials. \n",
    "\n",
    "**mem0** uses the following order of credentials when authenticating Azure OpenAI and Azure AI Search resources when an API is NOT provided. If a API key is provided it takes priority over Azure Identity credentials.\n",
    "\n",
    "1. **Environment Credential:**\n",
    "Azure client ID, secret, tenant ID, or certificate in environment variables for service principal authentication.\n",
    "\n",
    "2. **Workload Identity Credential:**\n",
    "Utilizes Azure Workload Identity (relevant for Kubernetes and Azure workloads).\n",
    "\n",
    "3. **Managed Identity Credential:**\n",
    "Authenticates as a Managed Identity (for apps/services hosted in Azure with Managed Identity enabled), this is the most secure production credential.\n",
    "\n",
    "4. **Shared Token Cache Credential / Visual Studio Credential (Windows only):**\n",
    "Uses cached credentials from Visual Studio sign-ins (and sometimes VS Code if SSO is enabled).\n",
    "\n",
    "5. **Azure CLI Credential:**\n",
    "Uses the currently logged-in user from the Azure CLI (`az login`), this is the most common development credential.\n",
    "\n",
    "6. **Azure PowerShell Credential:**\n",
    "Uses the identity from Azure PowerShell (`Connect-AzAccount`).\n",
    "\n",
    "7. **Azure Developer CLI Credential:**\n",
    "Uses the session from Azure Developer CLI (`azd auth login`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### 1. Install Mem0\n",
    "\n",
    "To use Mem0, install it using pip:\n",
    "\n",
    "```bash\n",
    "pip install \"mem0ai\"\n",
    "```\n",
    "\n",
    "### 2. Azure Credential setup\n",
    "\n",
    "This example will utilize your Entra Id account for a local credential. The most command local credential used is the Azure CLI Credential (az login). The [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/?view=azure-cli-latest) must be installed on your development workstation for th is example.\n",
    "\n",
    "### *Azure OpenAI setup*\n",
    "\n",
    "#### Step A:  Enable Role-Based Access Control (RBAC) for Azure OpenAI\n",
    "\n",
    "- In the Azure portal, go to your **Azure OpenAI** resource.\n",
    "- Select **Access control (IAM)** in the left-hand menu. This is where you will manage role assignments for RBAC.\n",
    "\n",
    "#### Step B: Assign Permissions to Your Entra ID Account\n",
    "\n",
    "- Click **Add** > **Add role assignment**.\n",
    "- For general read/write (data plane) access to Azure OpenAI, use:\n",
    "    - **Cognitive Services OpenAI Contributor** – for full management (read/write/deploy models).\n",
    "- On the **Members** tab, choose:\n",
    "    - For your development account: select **User** and pick your Azure Entra ID account (the same used with `az login`).\n",
    "- Click **Review + assign**.\n",
    "\n",
    "### *Azure AI Search setup*\n",
    "\n",
    "To allow your Azure Entra ID account to have read/write access to your Azure AI Search instance using Azure Identity, follow these steps:\n",
    "\n",
    "#### Step C: Enable Role-Based Access Control (RBAC) for Azure AI Search\n",
    "\n",
    "1. In the Azure Portal, navigate to your **Azure AI Search** service.\n",
    "2. In the left menu, select **Settings** > **Keys**.\n",
    "3. Change the authentication setting to **Role-based access control**, or to **Both** if you need API key compatibility. The default is “Key-based authentication”—you must switch it to use Azure roles.\n",
    "\n",
    "#### Step D: Assign Permissions to Your Entra ID Account\n",
    "\n",
    "1. **Go to Access Control (IAM):**\n",
    "    - In the Azure Portal, select your Search service.\n",
    "    - Click **Access Control (IAM)** on the left.\n",
    "2. **Add a Role Assignment:**\n",
    "    - Click **Add** > **Add role assignment**.\n",
    "3. **Choose Role:**\n",
    "    - For full data plane read/write access, select the **Search Service Contributor** role.\n",
    "    - You can also use or clone existing built-in roles or create a custom role if more granularity is needed (e.g., specific indexes).\n",
    "4. **Assign to User or Identity:**\n",
    "    - Choose **User** and select your Entra ID account (the one used for `az login`).\n",
    "5. **Complete the Assignment:**\n",
    "    - Click **Review + Assign**.\n",
    "\n",
    "#### Step E: Login to Azure\n",
    "\n",
    "1. Install Azure CLI if not already installed, check your installation using the following command.\n",
    "\n",
    "```bash\n",
    "az --version\n",
    "```\n",
    "\n",
    "2. Open a command terminal issue the following command.\n",
    "\n",
    "```bash\n",
    "az login\n",
    "```\n",
    "\n",
    "Your default browser will open in order for you to login to Azure.  Once you login return to your terminal session.\n",
    "\n",
    "3. Select your Azure Subscription if multiple are available.\n",
    "\n",
    "You're now ready to execute the **mem0** using Azure resources and Azure Identity credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from mem0 import Memory\n",
    "\n",
    "# Change these constants to your Azure OpenAI and Azure AI Search configurations\n",
    "azure_openai_chat_model = \"<your-azure-model>\"  # e.g., \"gpt-4o\n",
    "azure_openai_endpoint = \"<your-azure-endpoint>\"  # e.g., \"https://your-azure-openai-endpoint.openai.azure.com/\"\n",
    "azure_openai_chat_deployment = \"<your-azure-deployment>\"  # e.g., \"gpt-4o\"\n",
    "azure_openai_chat_api_version = \"<your-api-version>\"  # e.g., \"2024-12-01-preview\"\n",
    "\n",
    "azure_openai_embedding_model = \"<your-embedding-model-name>\"  # e.g., \"text-embedding-3-large\"\n",
    "azure_openai_embedding_endpoint = (\n",
    "    \"<your-azure-endpoint>\"  # e.g., \"https://your-azure-openai-endpoint.openai.azure.com/\"\n",
    ")\n",
    "azure_openai_embedding_deployment = \"<your-embedding-deployment>\"  # e.g., \"text-embedding-3-large\"\n",
    "azure_openai_embedding_api_version = \"<your-embedding-api-version>\"  # e.g., \"2024-02-01\"\n",
    "\n",
    "azure_search_service_name = \"<your-azure-search-service-name>\"  # e.g., \"my-aiss\" (name of the Azure AI Search resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create **mem0** configuration\n",
    "\n",
    "1. LLM uses Azure OpenAI\n",
    "2. Embedder uses Azure OpenAI\n",
    "3. Vector Store uses Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"llm\": {\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"config\": {\n",
    "            \"model\": azure_openai_chat_model,\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"azure_kwargs\": {\n",
    "                \"azure_endpoint\": azure_openai_endpoint,\n",
    "                \"azure_deployment\": azure_openai_chat_deployment,\n",
    "                \"api_version\": azure_openai_chat_api_version,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"config\": {\n",
    "            \"model\": azure_openai_embedding_model,\n",
    "            \"azure_kwargs\": {\n",
    "                \"azure_endpoint\": azure_openai_embedding_endpoint,\n",
    "                \"azure_deployment\": azure_openai_embedding_deployment,\n",
    "                \"api_version\": azure_openai_embedding_api_version,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"azure_ai_search\",\n",
    "        \"config\": {\n",
    "            \"service_name\": azure_search_service_name,\n",
    "            \"collection_name\": \"mem0\",\n",
    "            \"embedding_model_dims\": 3072,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Configuration for Azure OpenAI and Azure AI Search.\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the configuration to create a Memory instance\n",
    "m = Memory.from_config(config_dict=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store memories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a memory as a set of chat messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"How about a thriller movies? They can be quite engaging.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm not a big fan of thriller movies but I love sci-fi movies.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\",\n",
    "    },\n",
    "]\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=\"alice\", metadata={\"category\": \"movie_recommendations\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search stored memories\n",
    "for result in m.search(\"what does alice love?\", user_id=\"alice\")[\"results\"]:\n",
    "    print(result[\"memory\"], result[\"score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_py_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
