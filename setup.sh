#!/usr/bin/env bash
set -euo pipefail

# Mem0 project bootstrap for CI/cloud agents
# - Installs Python tooling (hatch) and sets up envs
# - Prepares minimal env files to run tests without external services
# - Optionally verifies Node workspaces (mem0-ts, vercel-ai-sdk)
# - Documents required secrets via env variables

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

color() { echo -e "\033[1;34m$*\033[0m"; }
warn() { echo -e "\033[1;33m$*\033[0m"; }
err()  { echo -e "\033[1;31m$*\033[0m"; }

need() {
  if ! command -v "$1" >/dev/null 2>&1; then
    err "Missing required command: $1"
    return 1
  fi
}

install_hatch() {
  if command -v hatch >/dev/null 2>&1; then
    color "hatch already installed"
    return 0
  fi
  if command -v pipx >/dev/null 2>&1; then
    color "Installing hatch via pipx"
    pipx install hatch
  else
    warn "pipx not found; installing hatch into user site-packages via pip"
    python3 -m pip install --user --upgrade hatch
    # ensure user base bin is on PATH for this session
    export PATH="$(python3 -c 'import site,sys; sys.stdout.write(site.USER_BASE + "/bin\n")'):$PATH"
  fi
}

python_bootstrap() {
  need python3 || return 1
  color "Ensuring hatch is available"
  install_hatch
  color "Creating hatch environments (make install)"
  make install
}

prepare_envs() {
  color "Preparing minimal env for tests"

  # Provide a safe default for tests; real runs should inject real keys
  : "${OPENAI_API_KEY:=test-key}"

  # Root-level .env for convenience (not required by tests)
  if [ ! -f "$ROOT_DIR/.env.example" ]; then
    cat > "$ROOT_DIR/.env.example" <<'EOF'
# Example top-level env (not loaded automatically by tools)
# Export in CI as needed. Do not commit real secrets.
OPENAI_API_KEY=
# Optional providers
TOGETHER_API_KEY=
GROQ_API_KEY=
GOOGLE_API_KEY=
GOOGLE_APPLICATION_CREDENTIALS=
EMBEDDING_AZURE_OPENAI_API_KEY=
EMBEDDING_AZURE_DEPLOYMENT=
EMBEDDING_AZURE_ENDPOINT=
EMBEDDING_AZURE_API_VERSION=
LLM_AZURE_OPENAI_API_KEY=
LLM_AZURE_DEPLOYMENT=
LLM_AZURE_ENDPOINT=
LLM_AZURE_API_VERSION=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=
AWS_REGION=
EOF
  fi

  # openmemory/api: minimal env to keep tests local (SQLite)
  if [ ! -f "$ROOT_DIR/openmemory/api/.env" ]; then
    warn "Creating openmemory/api/.env for local tests (SQLite)"
    cat > "$ROOT_DIR/openmemory/api/.env" <<EOF
# Generated by setup.sh for local/in-CI tests
# This uses SQLite and a dummy key to avoid external calls.
OPENAI_API_KEY=${OPENAI_API_KEY}
LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small
DATABASE_URL=sqlite:///./openmemory.db
# Optional: Redis/Neo4j/Qdrant not required for tests due to fakes/mocks
ENABLE_CREATE_ALL=true
ENABLE_DEEP_READINESS=false
USER=
EOF
  else
    warn "openmemory/api/.env exists; leaving as-is"
  fi

  # openmemory/.env: copy template if missing (do not fill secrets)
  if [ -f "$ROOT_DIR/openmemory/.env.template" ] && [ ! -f "$ROOT_DIR/openmemory/.env" ]; then
    warn "Copying openmemory/.env from template"
    cp "$ROOT_DIR/openmemory/.env.template" "$ROOT_DIR/openmemory/.env"
  fi
}

node_setup() {
  if ! command -v node >/dev/null 2>&1; then
    warn "node not found; skipping JS/TS workspaces (mem0-ts, vercel-ai-sdk)"
    return 0
  fi
  node_ver=$(node -v | sed 's/v//')
  color "Detected node v${node_ver}"
  (cd "$ROOT_DIR/mem0-ts" && \( [ -f package.json ] && npm ci && npm run build \) || true)
  (cd "$ROOT_DIR/vercel-ai-sdk" && \( [ -f package.json ] && npm ci && npm test --silent || true \))
}

docker_notes() {
  cat <<'EOF'
Docker/Compose (optional for local stack):
  - openmemory/docker-compose.yml defines qdrant, postgres, neo4j, API and UI.
  - Requires a Traefik network for routed deployments:
      docker network create traefik   # once per host
  - For local-only API dev/tests, Docker is not required; SQLite is used.
EOF
}

run_checks() {
  color "Running format/lint quick checks"
  make format
  make lint
  color "Running Python tests (env with extras)"
  # Prefer the 3.12 dev env which includes extras per pyproject.
  if make -q test-py-3.12 2>/dev/null; then
    make test-py-3.12
  else
    warn "Fallback to default test target"
    make test
  fi
}

show_summary() {
  cat <<'EOF'
Required secrets (inject via CI or before running code):
  - OPENAI_API_KEY: needed for real LLM/embedding usage (tests use a dummy).
Optional providers (set if you exercise these backends):
  - TOGETHER_API_KEY, GROQ_API_KEY, GOOGLE_API_KEY or GOOGLE_APPLICATION_CREDENTIALS
  - EMBEDDING_AZURE_OPENAI_API_KEY, EMBEDDING_AZURE_DEPLOYMENT, EMBEDDING_AZURE_ENDPOINT, EMBEDDING_AZURE_API_VERSION
  - LLM_AZURE_OPENAI_API_KEY, LLM_AZURE_DEPLOYMENT, LLM_AZURE_ENDPOINT, LLM_AZURE_API_VERSION
  - AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_REGION
Vector stores (auto-detected by env in OpenMemory):
  - QDRANT_HOST/QDRANT_PORT | CHROMA_HOST/CHROMA_PORT | WEAVIATE_CLUSTER_URL
  - REDIS_URL | PG_HOST/PG_PORT[/PG_DB/PG_USER/PG_PASSWORD] | MILVUS_HOST/MILVUS_PORT[/MILVUS_TOKEN]
  - ELASTICSEARCH_HOST/ELASTICSEARCH_PORT[/ELASTICSEARCH_USER/ELASTICSEARCH_PASSWORD]
  - OPENSEARCH_HOST/OPENSEARCH_PORT | FAISS_PATH
OpenMemory API runtime (when using docker-compose):
  - DATABASE_URL (Postgres DSN), NEO4J_URI/NEO4J_USERNAME/NEO4J_PASSWORD, OPENAI_API_KEY
  - Optional: CORS_ALLOWED_ORIGINS, ALLOWED_HOSTS, SECRET_KEY, REDIS_* for caching

Next steps:
  - To build/test Python:   make format lint test
  - To build mem0-ts:       (cd mem0-ts && npm ci && npm run build)
  - To test vercel provider: (cd vercel-ai-sdk && npm ci && npm test)
  - To run local API quickly: (cd openmemory/api && python -m uvicorn main:app --reload)
EOF
}

main() {
  color "==> Python bootstrap"
  python_bootstrap
  color "==> Prepare env files"
  prepare_envs
  color "==> Optional Node workspaces"
  node_setup || true
  color "==> Notes"
  docker_notes
  color "==> Validation"
  run_checks
  color "==> Summary"
  show_summary
}

main "$@"
