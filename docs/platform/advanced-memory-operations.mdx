---
title: Advanced Memory Operations
description: "Run richer add/search/update/delete flows on the managed platform with metadata, rerankers, and per-request controls."
---

# Make Platform Memory Operations Smarter

<Info>
  **Prerequisites**
  - Platform workspace with API key
  - Python 3.10+ and Node.js 18+
  - Async memories enabled in your dashboard (Settings → Memory Options)
</Info>

<Tip>
  Need a refresher on the core concepts first? Review the <Link href="/core-concepts/memory-operations/add">Add Memory</Link> overview, then come back for the advanced flow.
</Tip>

## Install and authenticate

<Tabs>
  <Tab title="Python">
<Steps>
<Step title="Install the SDK with async extras">
```bash
pip install "mem0ai[async]"
```
</Step>
<Step title="Export your API key">
```bash
export MEM0_API_KEY="sk-platform-..."
```
</Step>
<Step title="Create an async client">
```python
import os
from mem0 import AsyncMemoryClient

memory = AsyncMemoryClient(api_key=os.environ["MEM0_API_KEY"])
```
</Step>
</Steps>
  </Tab>
  <Tab title="TypeScript">
<Steps>
<Step title="Install the OSS SDK">
```bash
npm install mem0ai
```
</Step>
<Step title="Load your API key">
```bash
export MEM0_API_KEY="sk-platform-..."
```
</Step>
<Step title="Instantiate the client">
```typescript
import { Memory } from "mem0ai";

const memory = new Memory({ apiKey: process.env.MEM0_API_KEY!, async: true });
```
</Step>
</Steps>
  </Tab>
</Tabs>

## Add memories with metadata and graph context

<Tabs>
  <Tab title="Python">
<Steps>
<Step title="Record conversations with metadata">
```python
conversation = [
    {"role": "user", "content": "I'm Morgan, planning a 3-week trip to Japan in May."},
    {"role": "assistant", "content": "Great! I'll track dietary notes and cities you mention."},
    {"role": "user", "content": "Please remember I avoid shellfish and prefer boutique hotels in Tokyo."},
]

result = await memory.add(
    conversation,
    user_id="traveler-42",
    metadata={"trip": "japan-2025", "preferences": ["boutique", "no-shellfish"]},
    enable_graph=True,
    run_id="planning-call-1",
)
```
</Step>
</Steps>
  </Tab>
  <Tab title="TypeScript">
<Steps>
<Step title="Capture context-rich memories">
```typescript
const conversation = [
  { role: "user", content: "I'm Morgan, planning a 3-week trip to Japan in May." },
  { role: "assistant", content: "Great! I'll track dietary notes and cities you mention." },
  { role: "user", content: "Please remember I avoid shellfish and love boutique hotels in Tokyo." },
];

const result = await memory.add(conversation, {
  userId: "traveler-42",
  metadata: { trip: "japan-2025", preferences: ["boutique", "no-shellfish"] },
  enableGraph: true,
  runId: "planning-call-1",
});
```
</Step>
</Steps>
  </Tab>
</Tabs>

<Info icon="check">
  Successful calls return memories tagged with the metadata you passed. In the dashboard, confirm a graph edge between “Morgan” and “Tokyo” and verify the `trip=japan-2025` tag exists.
</Info>

## Retrieve and refine

<Tabs>
  <Tab title="Python">
<Steps>
<Step title="Filter by metadata + reranker">
```python
matches = await memory.search(
    "Any food alerts?",
    user_id="traveler-42",
    filters={"metadata.trip": "japan-2025"},
    rerank=True,
    include_vectors=False,
)
```
</Step>
<Step title="Update a memory inline">
```python
await memory.update(
    memory_id=matches["results"][0]["id"],
    content="Morgan avoids shellfish and prefers boutique hotels in central Tokyo.",
)
```
</Step>
</Steps>
  </Tab>
  <Tab title="TypeScript">
<Steps>
<Step title="Search with metadata filters">
```typescript
const matches = await memory.search("Any food alerts?", {
  userId: "traveler-42",
  filters: { "metadata.trip": "japan-2025" },
  rerank: true,
  includeVectors: false,
});
```
</Step>
<Step title="Apply an update">
```typescript
await memory.update(matches.results[0].id, {
  content: "Morgan avoids shellfish and prefers boutique hotels in central Tokyo.",
});
```
</Step>
</Steps>
  </Tab>
</Tabs>

<Tip>
  Need to pause graph writes on a per-request basis? Pass `enableGraph: false` (TypeScript) or `enable_graph=False` (Python) when latency matters more than relationship building.
</Tip>

## Clean up

<Tabs>
  <Tab title="Python">
<Steps>
<Step title="Delete scoped memories">
```python
await memory.delete_all(user_id="traveler-42", run_id="planning-call-1")
```
</Step>
</Steps>
  </Tab>
  <Tab title="TypeScript">
<Steps>
<Step title="Remove the run">
```typescript
await memory.deleteAll({ userId: "traveler-42", runId: "planning-call-1" });
```
</Step>
</Steps>
  </Tab>
</Tabs>

## Quick recovery

- `Missing required key enableGraph`: update the SDK to `mem0ai>=0.4.0`.
- `Graph backend unavailable`: retry with `enableGraph=False` and inspect your graph provider status.
- Empty results with filters: log `filters` values and confirm metadata keys match (case-sensitive).

<Warning>
  Metadata keys become part of your filtering schema. Stick to lowercase snake_case (`trip_id`, `preferences`) to avoid collisions down the road.
</Warning>

<CardGroup cols={2}>
  <Card
    title="Tune Metadata Filtering"
    description="Layer field-level filters on top of advanced operations."
    icon="funnel"
    href="/open-source/features/metadata-filtering"
  />
  <Card
    title="Explore Reranker Search"
    description="See how rerankers boost accuracy after vector + graph retrieval."
    icon="sparkles"
    href="/open-source/features/reranker-search"
  />
</CardGroup>
