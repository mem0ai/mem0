---
title: "Overview"
description: "Managed memory layer for AI agents - production-ready in minutes"
icon: "cloud"
---

# Mem0 Platform Overview

Mem0 is the memory engine that keeps conversations contextual so users never repeat themselves and your agents respond with continuity. Mem0 Platform delivers that experience as a fully managed service—scaling, securing, and enriching memories without any infrastructure work on your side.

<Tip>
  Mem0 v1.0.0 shipped rerankers, async-by-default behavior, and Azure OpenAI support. Catch the full list of changes in the <Link href="/changelog">release notes</Link>.
</Tip>

## Why it matters

- **Personalized replies**: Memories persist across users and agents, cutting prompt bloat and repeat questions.
- **Hosted stack**: Mem0 runs the vector store, graph services, and rerankers—no provisioning, tuning, or maintenance.
- **Enterprise controls**: SOC 2, audit logs, and workspace governance ship by default for production readiness.

<AccordionGroup>
  <Accordion title="What you get with Mem0 Platform" icon="sparkles">

    | Feature | Why it helps |
    | --- | --- |
    | Fast setup | Add a few lines of code and you’re production-ready—no vector database or LLM configuration required. |
    | Production scale | Automatic scaling, high availability, and managed infrastructure so you focus on product work. |
    | Advanced features | Graph memory, webhooks, multimodal support, and custom categories are ready to enable. |
    | Enterprise ready | SOC 2 Type II, GDPR compliance, and dedicated support keep security and governance covered. |
  </Accordion>
</AccordionGroup>

<Info>
  Start with the <Link href="/platform/quickstart">Platform quickstart</Link> to provision your workspace, then pick the journey below that matches your next milestone.
</Info>

## Choose your path

<CardGroup cols={3}>
  <Card title="Launch Your Workspace" icon="rocket" href="/platform/quickstart">
    Create project and ship first memory.
  </Card>
  <Card title="Connect Any AI Client" icon="puzzle-piece" href="/platform/mem0-mcp">
    Use MCP for universal AI integration.
  </Card>
  <Card title="Understand Memory Types" icon="brain" href="/core-concepts/memory-types">
    User, agent, and session memory behavior.
  </Card>
</CardGroup>

<CardGroup cols={3}>
  <Card title="Master Core Operations" icon="circle-check" href="/core-concepts/memory-operations/add">
    Add, search, update, and delete workflows.
  </Card>
  <Card title="Explore Platform Features" icon="sparkles" href="/platform/features/platform-overview">
    Graph memory, async clients, and rerankers.
  </Card>
  <Card title="Configure Advanced Operations" icon="bolt" href="/platform/advanced-memory-operations">
    Metadata filters and per-request toggles.
  </Card>
</CardGroup>

<CardGroup cols={2}>
  <Card title="Connect Integrations" icon="plug" href="/integrations">
    LangChain, CrewAI, Vercel AI SDK.
  </Card>
  <Card title="Monitor in the Dashboard" icon="presentation" href="https://app.mem0.ai">
    Track activity and manage workspaces.
  </Card>
</CardGroup>

<Tip>
  Evaluating self-hosting instead? Jump to the <Link href="/platform/platform-vs-oss">Platform vs OSS comparison</Link> to see trade-offs before you commit.
</Tip>

## Keep going

{/* DEBUG: verify CTA targets */}

<CardGroup cols={2}>
  <Card
    title="Compare with Open Source"
    description="Review feature parity, migration paths, and when to stay managed."
    icon="arrows-left-right"
    href="/platform/platform-vs-oss"
  />
  <Card
    title="Run the Quickstart"
    description="Provision your workspace, install the SDK, and persist your first memory."
    icon="rocket"
    href="/platform/quickstart"
  />
</CardGroup>
