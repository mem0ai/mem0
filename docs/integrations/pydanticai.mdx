---
title: PydanticAI
description: Integrate Mem0 with PydanticAI to create AI agents with long-term memory.
---

Integrate [**Mem0**](https://github.com/mem0ai/mem0) with [PydanticAI](https://ai.pydantic.dev), a powerful framework for building AI agents. This integration enhances PydanticAI agents with persistent memory capabilities, enabling more contextual and personalized interactions.

## Overview

This guide demonstrates how to build a PydanticAI agent that:

1.  Leverages Mem0 to store and retrieve relevant information from past interactions.
2.  Maintains context across conversations for personalized responses.
3.  Improves decision-making by utilizing historical data.

By combining Mem0's memory layer with PydanticAI's structured agent capabilities, you can create robust AI applications that learn and adapt over time.

## Setup and Configuration

Before you begin, ensure you have:

1.  Installed the required packages:

    ```bash
    pip install mem0ai pydantic-ai python-dotenv
    ```

2.  Valid API keys:
    -   [Mem0 API Key](https://app.mem0.ai/dashboard/api-keys)
    -   **PydanticAI Model API Key:** Depending on the LLM you choose (e.g., OpenAI, Grok, Gemini), set the corresponding API key as an environment variable (e.g., `OPENAI_API_KEY`, `GROQ_API_KEY`, `GOOGLE_API_KEY`). PydanticAI is model-agnostic, allowing easy switching between different LLM providers.

### Initialize Clients and Agent

First, import necessary modules, set up environment variables, and initialize Mem0 and your PydanticAI agent.

```python
import os
from typing import List
from pydantic_ai import Agent, ModelMessage, UserPromptPart, RunContext, SystemPromptPart, ModelRequest
from mem0 import MemoryClient
from dotenv import load_dotenv

load_dotenv()

# Configuration: Set your API keys as environment variables
# os.environ["MEM0_API_KEY"] = "your-mem0-api-key"
# os.environ["OPENAI_API_KEY"] = "your-openai-api-key" # Example for PydanticAI agent model

# Initialize Mem0 client
mem0 = MemoryClient()

# Initialize PydanticAI Agent
agent = Agent(
    'openai:gpt-4o-mini', # Replace with your desired model
    instructions='You are a helpful AI assistant that remembers user preferences.'
)
```

### Define Memory Helper Functions

These functions handle searching and adding memories to Mem0.

```python
def retrieve_memories(query: str, user_id: str) -> str:
    """Retrieve relevant memories from Mem0 based on the query and user_id."""
    memories = mem0.search(query, user_id=user_id)
    if memories:
        return "\nRelevant past memories:\n" + "\n".join([f"- {mem['memory']}" for mem in memories])
    return ""

def save_conversation(user_id: str, user_input: str, assistant_response: str):
    """Save the user input and assistant response to Mem0 for a specific user."""
    conversation = [
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": assistant_response},
    ]
    mem0.add(conversation, user_id=user_id)
```

### Integrate Mem0 with PydanticAI using `history_processors`

PydanticAI's `history_processors` modify the message history before it's sent to the LLM, allowing us to inject relevant memories.

```python
async def mem0_history_processor(ctx: RunContext[str], messages: List[ModelMessage]) -> List[ModelMessage]:
    """Injects Mem0 memories into the PydanticAI agent's context using the user_id from RunContext."""
    user_id = ctx.deps # user_id is passed as a dependency

    # Get the latest user message to query Mem0
    latest_user_message = ""
    for msg in reversed(messages):
        if isinstance(msg.parts[0], UserPromptPart):
            latest_user_message = msg.parts[0].content
            break

    if latest_user_message:
        relevant_memories_str = retrieve_memories(latest_user_message, user_id)
        if relevant_memories_str:
            # Prepend memories as a SystemPromptPart within a ModelRequest
            messages.insert(0, ModelRequest(parts=[SystemPromptPart(content=relevant_memories_str)]))

    return messages

# Re-initialize the agent with the history processor and specify dependency type
agent_with_memory = Agent(
    'openai:gpt-4o-mini',
    instructions='You are a helpful AI assistant that remembers user preferences.',
    history_processors=[mem0_history_processor],
    deps_type=str # Specifies that user_id (a string) will be passed as a dependency
)
```

### Chat Function

This function orchestrates the interaction with the PydanticAI agent and Mem0.

```python
async def chat_with_mem0_pydanticai(user_input: str, user_id: str = "default_user") -> str:
    """Sends a query to the PydanticAI agent and saves the conversation to Mem0."""
    # The `user_id` is passed as a dependency (`deps`) to the agent's run.
    # This `user_id` is then accessible within the `mem0_history_processor` via `ctx.deps`.
    # We pass an empty `message_history` here because the `mem0_history_processor` is responsible
    # for injecting relevant memories into the message history before the agent processes it.
    result = await agent_with_memory.run(user_input, message_history=[], deps=user_id)
    assistant_response = result.output

    # Save the full conversation turn to Mem0
    save_conversation(user_id, user_input, assistant_response)

    return assistant_response
```

### Usage Example

Demonstrates a multi-turn conversation with memory recall.

```python
import asyncio

async def main():
    user_id = "john_doe"

    print("--- First Interaction ---")
    response1 = await chat_with_mem0_pydanticai("My name is John and I like to hike.", user_id=user_id)
    print(f"AI: {response1}")

    print("\n--- Second Interaction ---")
    response2 = await chat_with_mem0_pydanticai("What is my name and what do I like to do?", user_id=user_id)
    print(f"AI: {response2}")

    print("\n--- Third Interaction ---")
    response3 = await chat_with_mem0_pydanticai("Suggest a good hiking trail for me.", user_id=user_id)
    print(f"AI: {response3}")

if __name__ == "__main__":
    asyncio.run(main())
```

## How It Works

The integration between Mem0 and PydanticAI follows these steps:

1.  **User Input**: A user sends a message to the `chat_with_mem0_pydanticai` function.
2.  **Memory Retrieval (via `history_processors`)**: Before the PydanticAI agent processes the message, the `mem0_history_processor` intercepts the message history. It uses the latest user message to query Mem0 for relevant past memories.
3.  **Prompt Enrichment**: The retrieved memories are then injected as a `SystemPromptPart` into the message history, providing the PydanticAI agent with crucial context.
4.  **PydanticAI Processing**: The PydanticAI agent processes the enriched prompt and generates a response.
5.  **Memory Storage**: The entire conversation turn (user message and AI response) is then stored back into Mem0 using the `save_conversation` function, ensuring that future interactions can leverage this new information.

## Key Features

1.  **Persistent Memory**: Mem0 stores and retrieves relevant information across interactions.
2.  **Contextual Conversations**: PydanticAI agents leverage injected memories for personalized responses.
3.  **Enhanced Personalization**: Tailors interactions based on user history and preferences.
4.  **Flexible Integration**: Uses PydanticAI's `history_processors` for seamless memory injection.

## Conclusion

By integrating Mem0 with PydanticAI using `history_processors`, you can build intelligent and personalized AI agents that remember past interactions, understand context, and provide accurate and relevant responses. This approach is ideal for applications requiring ongoing user engagement and a deep understanding of individual user histories.

## Help

-   [PydanticAI Documentation](https://ai.pydantic.dev)
-   [Mem0 Platform](https://app.mem0.ai/)

<Snippet file="get-help.mdx" />
