---
title: Overview
icon: "arrow-up-arrow-down"
iconType: "solid"
---

Mem0 includes built-in support for various reranking providers to improve the relevance of memory search results. Rerankers post-process initial vector search results by re-scoring and re-ordering them using more sophisticated relevance models.

## Usage

To use a reranker:

1. **Configure**: Add a `rerank` configuration section in your memory config
2. **Search**: Reranking is automatically enabled for all searches (default: `rerank=True`)

If no reranker is configured, search results will rely on vector similarity scoring alone.

For comprehensive configuration parameters for each reranker, please refer to [Config](./config).

### Controlling Reranking Per Search

Once configured, reranking is enabled by default. You can control it per-search:

```python
# Reranking enabled (default)
results = memory.search("query", user_id="user1")

# Explicitly enable reranking
results = memory.search("query", user_id="user1", rerank=True)

# Disable reranking for this specific search
results = memory.search("query", user_id="user1", rerank=False)
```

## How Reranking Works

1. **Initial Search**: Vector similarity search retrieves candidate memories
2. **Reranking** (if enabled): Selected reranker re-scores candidates using advanced models
3. **Final Results**: Re-ordered results with both vector and rerank scores

<Note>
Reranking operates as a post-processing step and can significantly improve search relevance at the cost of additional latency and API calls.
</Note>

## Supported Rerankers

See the list of supported rerankers below.

<CardGroup cols={2}>
  <Card title="Zero Entropy" href="/components/rerankers/models/zero_entropy" />
  <Card title="Cohere" href="/components/rerankers/models/cohere" />
  <Card title="Sentence Transformer" href="/components/rerankers/models/sentence_transformer" />
  <Card title="Hugging Face" href="/components/rerankers/models/huggingface" />
  <Card title="LLM-based" href="/components/rerankers/models/llm" />
  <Card title="LLM Reranker" href="/components/rerankers/models/llm_reranker" />
</CardGroup>

## When to Use Reranking

- **Improved Relevance**: When vector search alone doesn't provide sufficiently relevant results
- **Domain-Specific Queries**: For specialized terminology or context that benefits from advanced models
- **Quality vs Speed Trade-off**: When you can accept higher latency for better search quality
- **Production Systems**: Where search quality directly impacts user experience

Choose the reranker that best fits your use case:
- **Zero Entropy**: Best balance of speed and quality for general use
- **Cohere**: Enterprise-grade with excellent multilingual support
- **Sentence Transformer**: Local deployment for privacy-sensitive applications
- **Hugging Face**: Wide variety of pre-trained models for specialized use cases
- **LLM-based**: Maximum customization with custom prompts and logic
