---
title: Jan
---

You can download and run LLMs locally with [Jan](https://www.jan.ai/). 
Make sure to choose models that support tool calling.

## Usage
## Usage

```python
import os
from mem0 import Memory

config = {
    "llm": {
        "provider": "jan",
        "config": {
            "model": "openai_gpt-oss-20b-IQ2_M",
            "api_key": "<jan-server-api-key>",
            "jan_base_url": "http://localhost:1337/v1/",
            "temperature": 0.2,
            "max_tokens": 2000
        }
    }
}

m = Memory.from_config(config)

# For a user
messages = [
    {
        "role": "user",
        "content": "I like to drink coffee in the morning and go for a walk"
    }
]
result = m.add(messages, user_id="alice", metadata={"category": "preferences"})

related_memories = m.search("Should I drink coffee or tea?", user_id="alice")

print(related_memories)
```

See the quickstart example [here](../../../examples/jan-quickstart)


## Config

All available parameters for the `jan` config are present in [Master List of All Params in Config](../config).