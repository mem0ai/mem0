---
title: ðŸ¤– Large language models (LLMs)
---

## Overview

Embedchain comes with built-in support for various popular large language models. We handle the complexity of integrating these models for you, allowing you to easily customize your language model interactions through a user-friendly interface.

<CardGroup cols={4}>
  <Card title="OpenAI" href="#openai"></Card>
  <Card title="Google AI" href="#google-ai"></Card>
  <Card title="Azure OpenAI" href="#azure-openai"></Card>
  <Card title="Anthropic" href="#anthropic"></Card>
  <Card title="Cohere" href="#cohere"></Card>
  <Card title="Together" href="#together"></Card>
  <Card title="Ollama" href="#ollama"></Card>
  <Card title="vLLM" href="#vllm"></Card>
  <Card title="GPT4All" href="#gpt4all"></Card>
  <Card title="JinaChat" href="#jinachat"></Card>
  <Card title="Hugging Face" href="#hugging-face"></Card>
  <Card title="Llama2" href="#llama2"></Card>
  <Card title="Vertex AI" href="#vertex-ai"></Card>
  <Card title="Mistral AI" href="#mistral-ai"></Card>
  <Card title="AWS Bedrock" href="#aws-bedrock"></Card>
  <Card title="Groq" href="#groq"></Card>
  <Card title="NVIDIA AI" href="#nvidia-ai"></Card>
  <Card title="Zhipu AI" href="#zhipu-ai"></Card>
</CardGroup>

## OpenAI

To use OpenAI LLM models, you have to set the `OPENAI_API_KEY` environment variable. You can obtain the OpenAI API key from the [OpenAI Platform](https://platform.openai.com/account/api-keys).

Once you have obtained the key, you can use it like this:

```python
import os
from embedchain import App

os.environ['OPENAI_API_KEY'] = 'xxx'

app = App()
app.add("https://en.wikipedia.org/wiki/OpenAI")
app.query("What is OpenAI?")
```

If you are looking to configure the different parameters of the LLM, you can do so by loading the app using a [yaml config](https://github.com/embedchain/embedchain/blob/main/configs/chroma.yaml) file.

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ['OPENAI_API_KEY'] = 'xxx'

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: openai
  config:
    model: 'gpt-3.5-turbo'
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
    stream: false
```
</CodeGroup>

### Function Calling
Embedchain supports OpenAI [Function calling](https://platform.openai.com/docs/guides/function-calling) with a single function. It accepts inputs in accordance with the [Langchain interface](https://python.langchain.com/docs/modules/model_io/chat/function_calling#legacy-args-functions-and-function_call).

<Accordion title="Pydantic Model">
  ```python
  from pydantic import BaseModel

  class multiply(BaseModel):
      """Multiply two integers together."""

      a: int = Field(..., description="First integer")
      b: int = Field(..., description="Second integer")
  ```
</Accordion>

<Accordion title="Python function">
  ```python
  def multiply(a: int, b: int) -> int:
      """Multiply two integers together.

      Args:
          a: First integer
          b: Second integer
      """
      return a * b
  ```
</Accordion>
<Accordion title="OpenAI tool dictionary">
  ```python
  multiply = {
    "type": "function",
    "function": {
      "name": "multiply",
      "description": "Multiply two integers together.",
      "parameters": {
        "type": "object",
        "properties": {
          "a": {
            "description": "First integer",
            "type": "integer"
          },
          "b": {
            "description": "Second integer",
            "type": "integer"
          }
        },
        "required": [
          "a",
          "b"
        ]
      }
    }
  }
  ```
</Accordion>

With any of the previous inputs, the OpenAI LLM can be queried to provide the appropriate arguments for the function.

```python
import os
from embedchain import App
from embedchain.llm.openai import OpenAILlm

os.environ["OPENAI_API_KEY"] = "sk-xxx"

llm = OpenAILlm(tools=multiply)
app = App(llm=llm)

result = app.query("What is the result of 125 multiplied by fifteen?")
```

## Google AI

To use Google AI model, you have to set the `GOOGLE_API_KEY` environment variable. You can obtain the Google API key from the [Google Maker Suite](https://makersuite.google.com/app/apikey)

<CodeGroup>
```python main.py
import os
from embedchain import App

os.environ["GOOGLE_API_KEY"] = "xxx"

app = App.from_config(config_path="config.yaml")

app.add("https://www.forbes.com/profile/elon-musk")

response = app.query("What is the net worth of Elon Musk?")
if app.llm.config.stream: # if stream is enabled, response is a generator
    for chunk in response:
        print(chunk)
else:
    print(response)
```

```yaml config.yaml
llm:
  provider: google
  config:
    model: gemini-pro
    max_tokens: 1000
    temperature: 0.5
    top_p: 1
    stream: false

embedder:
  provider: google
  config:
    model: 'models/embedding-001'
    task_type: "retrieval_document"
    title: "Embeddings for Embedchain"
```
</CodeGroup>

## Azure OpenAI

To use Azure OpenAI model, you have to set some of the azure openai related environment variables as given in the code block below:

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["OPENAI_API_TYPE"] = "azure"
os.environ["OPENAI_API_BASE"] = "https://xxx.openai.azure.com/"
os.environ["OPENAI_API_KEY"] = "xxx"
os.environ["OPENAI_API_VERSION"] = "xxx"

app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: azure_openai
  config:
    model: gpt-3.5-turbo
    deployment_name: your_llm_deployment_name
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
    stream: false

embedder:
  provider: azure_openai
  config:
    model: text-embedding-ada-002
    deployment_name: you_embedding_model_deployment_name
```
</CodeGroup>

You can find the list of models and deployment name on the [Azure OpenAI Platform](https://oai.azure.com/portal).

## Anthropic

To use anthropic's model, please set the `ANTHROPIC_API_KEY` which you find on their [Account Settings Page](https://console.anthropic.com/account/keys).

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["ANTHROPIC_API_KEY"] = "xxx"

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: anthropic
  config:
    model: 'claude-instant-1'
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
    stream: false
```

</CodeGroup>

## Cohere

Install related dependencies using the following command:

```bash
pip install --upgrade 'embedchain[cohere]'
```

Set the `COHERE_API_KEY` as environment variable which you can find on their [Account settings page](https://dashboard.cohere.com/api-keys).

Once you have the API key, you are all set to use it with Embedchain.

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["COHERE_API_KEY"] = "xxx"

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: cohere
  config:
    model: large
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
```

</CodeGroup>

## Together

Install related dependencies using the following command:

```bash
pip install --upgrade 'embedchain[together]'
```

Set the `TOGETHER_API_KEY` as environment variable which you can find on their [Account settings page](https://api.together.xyz/settings/api-keys).

Once you have the API key, you are all set to use it with Embedchain.

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["TOGETHER_API_KEY"] = "xxx"

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: together
  config:
    model: togethercomputer/RedPajama-INCITE-7B-Base
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
```

</CodeGroup>

## Ollama

Setup Ollama using https://github.com/jmorganca/ollama

<CodeGroup>

```python main.py
import os
from embedchain import App

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: ollama
  config:
    model: 'llama2'
    temperature: 0.5
    top_p: 1
    stream: true
    base_url: 'http://localhost:11434'
```

</CodeGroup>


## vLLM

Setup vLLM by following instructions given in [their docs](https://docs.vllm.ai/en/latest/getting_started/installation.html).

<CodeGroup>

```python main.py
import os
from embedchain import App

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: vllm
  config:
    model: 'meta-llama/Llama-2-70b-hf'
    temperature: 0.5
    top_p: 1
    top_k: 10
    stream: true
    trust_remote_code: true
```

</CodeGroup>

## GPT4ALL

Install related dependencies using the following command:

```bash
pip install --upgrade 'embedchain[opensource]'
```

GPT4all is a free-to-use, locally running, privacy-aware chatbot. No GPU or internet required. You can use this with Embedchain using the following code:

<CodeGroup>

```python main.py
from embedchain import App

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: gpt4all
  config:
    model: 'orca-mini-3b-gguf2-q4_0.gguf'
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
    stream: false

embedder:
  provider: gpt4all
```
</CodeGroup>


## JinaChat

First, set `JINACHAT_API_KEY` in environment variable which you can obtain from [their platform](https://chat.jina.ai/api).

Once you have the key, load the app using the config yaml file:

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["JINACHAT_API_KEY"] = "xxx"
# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: jina
  config:
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
    stream: false
```
</CodeGroup>


## Hugging Face


Install related dependencies using the following command:

```bash
pip install --upgrade 'embedchain[huggingface-hub]'
```

First, set `HUGGINGFACE_ACCESS_TOKEN` in environment variable which you can obtain from [their platform](https://huggingface.co/settings/tokens).

You can load the LLMs from Hugging Face using three ways:

- [Hugging Face Hub](#hugging-face-hub)
- [Hugging Face Local Pipelines](#hugging-face-local-pipelines)
- [Hugging Face Inference Endpoint](#hugging-face-inference-endpoint)

### Hugging Face Hub

To load the model from Hugging Face Hub, use the following code:

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["HUGGINGFACE_ACCESS_TOKEN"] = "xxx"

config = {
  "app": {"config": {"id": "my-app"}},
  "llm": {
      "provider": "huggingface",
      "config": {
          "model": "bigscience/bloom-1b7",
          "top_p": 0.5,
          "max_length": 200,
          "temperature": 0.1,
      },
  },
}

app = App.from_config(config=config)
```
</CodeGroup>

### Hugging Face Local Pipelines

If you want to load the locally downloaded model from Hugging Face, you can do so by following the code provided below:

<CodeGroup>
```python main.py
from embedchain import App

config = {
  "app": {"config": {"id": "my-app"}},
  "llm": {
      "provider": "huggingface",
      "config": {
          "model": "Trendyol/Trendyol-LLM-7b-chat-v0.1",
          "local": True,  # Necessary if you want to run model locally
          "top_p": 0.5,
          "max_tokens": 1000,
          "temperature": 0.1,
      },
  }
}
app = App.from_config(config=config)
```
</CodeGroup>

### Hugging Face Inference Endpoint

You can also use [Hugging Face Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index#-inference-endpoints) to access custom endpoints. First, set the `HUGGINGFACE_ACCESS_TOKEN` as above.

Then, load the app using the config yaml file:

<CodeGroup>

```python main.py
from embedchain import App

config = {
  "app": {"config": {"id": "my-app"}},
  "llm": {
      "provider": "huggingface",
      "config": {
        "endpoint": "https://api-inference.huggingface.co/models/gpt2",
        "model_params": {"temprature": 0.1, "max_new_tokens": 100}
      },
  },
}
app = App.from_config(config=config)

```
</CodeGroup>

Currently only supports `text-generation` and `text2text-generation` for now [[ref](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html?highlight=huggingfaceendpoint#)].

See langchain's [hugging face endpoint](https://python.langchain.com/docs/integrations/chat/huggingface#huggingfaceendpoint) for more information. 

## Llama2

Llama2 is integrated through [Replicate](https://replicate.com/).  Set `REPLICATE_API_TOKEN` in environment variable which you can obtain from [their platform](https://replicate.com/account/api-tokens).

Once you have the token, load the app using the config yaml file:

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["REPLICATE_API_TOKEN"] = "xxx"

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: llama2
  config:
    model: 'a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5'
    temperature: 0.5
    max_tokens: 1000
    top_p: 0.5
    stream: false
```
</CodeGroup>

## Vertex AI

Setup Google Cloud Platform application credentials by following the instruction on [GCP](https://cloud.google.com/docs/authentication/external/set-up-adc). Once setup is done, use the following code to create an app using VertexAI as provider:

<CodeGroup>

```python main.py
from embedchain import App

# load llm configuration from config.yaml file
app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: vertexai
  config:
    model: 'chat-bison'
    temperature: 0.5
    top_p: 0.5
```
</CodeGroup>


## Mistral AI

Obtain the Mistral AI api key from their [console](https://console.mistral.ai/).

<CodeGroup>
 
 ```python main.py
os.environ["MISTRAL_API_KEY"] = "xxx"

app = App.from_config(config_path="config.yaml")

app.add("https://www.forbes.com/profile/elon-musk")

response = app.query("what is the net worth of Elon Musk?")
# As of January 16, 2024, Elon Musk's net worth is $225.4 billion.

response = app.chat("which companies does elon own?")
# Elon Musk owns Tesla, SpaceX, Boring Company, Twitter, and X.

response = app.chat("what question did I ask you already?")
# You have asked me several times already which companies Elon Musk owns, specifically Tesla, SpaceX, Boring Company, Twitter, and X.
```
  
```yaml config.yaml
llm:
  provider: mistralai
  config:
    model: mistral-tiny
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
embedder:
  provider: mistralai
  config:
    model: mistral-embed
```
</CodeGroup>


## AWS Bedrock

### Setup
- Before using the AWS Bedrock LLM, make sure you have the appropriate model access from [Bedrock Console](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess).
- You will also need to authenticate the `boto3` client by using a method in the [AWS documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html#configuring-credentials)
- You can optionally export an `AWS_REGION`


### Usage

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ["AWS_ACCESS_KEY_ID"] = "xxx"
os.environ["AWS_SECRET_ACCESS_KEY"] = "xxx"
os.environ["AWS_REGION"] = "us-west-2"

app = App.from_config(config_path="config.yaml")
```

```yaml config.yaml
llm:
  provider: aws_bedrock
  config:
    model: amazon.titan-text-express-v1
    # check notes below for model_kwargs
    model_kwargs:
      temperature: 0.5
      topP: 1
      maxTokenCount: 1000
```
</CodeGroup>

<br />
<Note>
  The model arguments are different for each providers. Please refer to the [AWS Bedrock Documentation](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers) to find the appropriate arguments for your model.
</Note>

<br/ >

## Groq

[Groq](https://groq.com/) is the creator of the world's first Language Processing Unit (LPU), providing exceptional speed performance for AI workloads running on their LPU Inference Engine.


### Usage

In order to use LLMs from Groq, go to their [platform](https://console.groq.com/keys) and get the API key.

Set the API key as `GROQ_API_KEY` environment variable or pass in your app configuration to use the model as given below in the example.

<CodeGroup>

```python main.py
import os
from embedchain import App

# Set your API key here or pass as the environment variable
groq_api_key = "gsk_xxxx"

config = {
    "llm": {
        "provider": "groq",
        "config": {
            "model": "mixtral-8x7b-32768",
            "api_key": groq_api_key,
            "stream": True
        }
    }
}

app = App.from_config(config=config)
# Add your data source here
app.add("https://docs.embedchain.ai/sitemap.xml", data_type="sitemap")
app.query("Write a poem about Embedchain")

# In the realm of data, vast and wide,
# Embedchain stands with knowledge as its guide.
# A platform open, for all to try,
# Building bots that can truly fly.

# With REST API, data in reach,
# Deployment a breeze, as easy as a speech.
# Updating data sources, anytime, anyday,
# Embedchain's power, never sway.

# A knowledge base, an assistant so grand,
# Connecting to platforms, near and far.
# Discord, WhatsApp, Slack, and more,
# Embedchain's potential, never a bore.
```
</CodeGroup>

## NVIDIA AI

[NVIDIA AI Foundation Endpoints](https://www.nvidia.com/en-us/ai-data-science/foundation-models/) let you quickly use NVIDIA's AI models, such as Mixtral 8x7B, Llama 2 etc, through our API. These models are available in the [NVIDIA NGC catalog](https://catalog.ngc.nvidia.com/ai-foundation-models), fully optimized and ready to use on NVIDIA's AI platform. They are designed for high speed and easy customization, ensuring smooth performance on any accelerated setup.


### Usage

In order to use LLMs from NVIDIA AI, create an account on [NVIDIA NGC Service](https://catalog.ngc.nvidia.com/).

Generate an API key from their dashboard. Set the API key as `NVIDIA_API_KEY` environment variable. Note that the `NVIDIA_API_KEY` will start with `nvapi-`.

Below is an example of how to use LLM model and embedding model from NVIDIA AI:

<CodeGroup>

```python main.py
import os
from embedchain import App

os.environ['NVIDIA_API_KEY'] = 'nvapi-xxxx'

config = {
    "app": {
        "config": {
            "id": "my-app",
        },
    },
    "llm": {
        "provider": "nvidia",
        "config": {
            "model": "nemotron_steerlm_8b",
        },
    },
    "embedder": {
        "provider": "nvidia",
        "config": {
            "model": "nvolveqa_40k",
            "vector_dimension": 1024,
        },
    },
}

app = App.from_config(config=config)

app.add("https://www.forbes.com/profile/elon-musk")
answer = app.query("What is the net worth of Elon Musk today?")
# Answer: The net worth of Elon Musk is subject to fluctuations based on the market value of his holdings in various companies.
# As of March 1, 2024, his net worth is estimated to be approximately $210 billion. However, this figure can change rapidly due to stock market fluctuations and other factors.
# Additionally, his net worth may include other assets such as real estate and art, which are not reflected in his stock portfolio.
```
</CodeGroup>

## Zhipu AI


### Usage

In order to use LLMs from Zhipu AI, create an account on [Zhipu AI open platform](https://open.bigmodel.cn/).

Generate an API key from their dashboard. Set the API key as `ZHIPU_API_KEY` environment variable.

Below is an example of how to use LLM model and embedding model from Zhipu AI:

<CodeGroup>

```python main.py
from embedchain import App
import os
os.environ["ZHIPU_API_KEY"]="your-zhipu-api-key"
config = {
  'llm': {
    'provider': 'zhipuai',
    'config': {
      'model': 'glm-4',
      'temperature':0.1,
      'top_p':0.1,
      "stream":False,
    }
  },
  'embedder': {
    'provider': 'huggingface',
    'config': {
      'model': 'sentence-transformers/all-mpnet-base-v2'
    }
  }
}
app = App.from_config(config=config)
app.add("https://baike.baidu.com/item/%E5%9F%83%E9%9A%86%C2%B7%E9%A9%AC%E6%96%AF%E5%85%8B/3776526?fr=ge_ala")
"""æµ‹è¯•ç”¨ä¾‹ï¼š
>>> app.query("é©¬æ–¯å…‹åœ¨2001å¹´åˆåšäº†ä»€ä¹ˆ")
åœ¨2001å¹´åˆï¼Œé©¬æ–¯å…‹è¿˜åœ¨è´å®æœŸé—´ï¼Œç­–åˆ’äº†ä¸€ä¸ªåä¸ºâ€œç«æ˜Ÿç»¿æ´²â€çš„é¡¹ç›®ï¼Œè®¡åˆ’å°†ä¸€ä¸ªå°åž‹å®žéªŒæ¸©å®¤é™è½åœ¨ç«æ˜Ÿä¸Šï¼Œä»¥å°è¯•è®©åœ°çƒçš„å†œä½œç‰©åœ¨ç«æ˜ŸåœŸå£¤ä¸­ç”Ÿé•¿ã€‚ç„¶è€Œï¼Œå½“ä»–å‘çŽ°è´­ä¹°ä¿„ç½—æ–¯å®‡èˆªå…¬å¸è¿è½½ç«ç®­çš„æˆæœ¬è¿œé«˜äºŽè‡ªè¡Œç ”å‘ç«ç®­çš„æˆæœ¬ï¼Œä¸”å‘å°„æˆæœ¬æ¯”é¡¹ç›®çš„ç ”å‘å’Œå·¥ç¨‹æˆæœ¬è¿˜è¦é«˜æ—¶ï¼Œä»–å†³å®šæš‚ç¼“è¿™ä¸ªé¡¹ç›®ï¼Œå¹¶æˆç«‹SpaceXå…¬å¸ï¼Œä»¥ç ”ç©¶å¦‚ä½•é™ä½Žå‘å°„æˆæœ¬ã€‚

>>> app.query("SpaceXç ”åˆ¶é¾™é£žèˆ¹2å·çš„æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™")
SpaceXä»Ž2014å¹´å¼€å§‹ç ”åˆ¶é£žèˆ¹2å·ã€‚

"""


"""å¤§æ¨¡åž‹å†…éƒ¨è¯¦æƒ…ã€‚
# ç¬¬ä¸€ä¸ªç¤ºä¾‹çš„user prompt
You are a Q&A expert system. Your responses must always be rooted in the context provided for each query. Here are some guidelines to follow:

1. Refrain from explicitly mentioning the context provided in your response.
2. The context should silently guide your answers without being directly acknowledged.
3. Do not use phrases such as 'According to the context provided', 'Based on the context, ...' etc.

Context information:
----------------------
[11]1984å¹´ï¼Œé©¬æ–¯å…‹æˆåŠŸè®¾è®¡å‡ºä¸€ä¸ªåå«â€œç‚¸å¼¹â€ï¼ˆBlastarï¼‰çš„å¤ªç©ºæ¸¸æˆè½¯ä»¶ï¼Œä¹‹åŽä»¥500ç¾Žå…ƒçš„ä»·æ ¼å‡ºå”®ç»™ã€ŠPC and Office Technologyã€‹æ‚å¿—ï¼Œèµšåˆ°äººç”Ÿçš„ç¬¬ä¸€æ¡¶é‡‘ã€‚ [12] [189]å°‘å¹´æ—¶ä»£å°‘å¹´æ—¶ä»£å°‘å¹´æ—¶ä»£ï¼ˆå·¦ï¼‰å°‘å¹´é©¬æ–¯å…‹ï¼ˆå³ä¸€ï¼‰ä¸Žæ¯äº²ï¼ˆå³äºŒï¼‰å©´å„¿æ—¶æœŸçš„é©¬æ–¯å…‹ä¸Žçˆ¶äº²æ•™è‚²ç»åŽ†é«˜ä¸­æ—¶æœŸï¼Œé©¬æ–¯å…‹å…ˆåœ¨å—éžçº¦ç¿°å†…æ–¯å ¡åŒ—éƒŠçš„å¸ƒå…°æ–¯é¡¿é«˜ä¸­ï¼ˆBryanston High Schoolï¼‰å°±è¯»ï¼Œ [190]å› ä¸ºå—åˆ°ä¸¥é‡æ¬ºè´Ÿï¼Œå°±è¯»ä¸¤å¹´åŽï¼Œçˆ¶äº²å¸®ä»–è½¬å­¦åˆ°ä¸€æ‰€ç§â½´å­¦æ ¡â€”æ¯”å‹’é™€åˆ©äºšç”·â¼¦ä¸­å­¦ï¼Œè¿™æ‰€å­¦æ ¡ä»¥è‹±å›½æ•™å­¦æ¨¡å¼ä¸ºåŸºç¡€ï¼Œæ ¡è§„ä¸¥æ ¼ï¼Œåœ¨é‚£â¾¥ï¼Œä»–çš„å­¦ä¹ æˆç»©éƒ½å¾ˆå¥½ï¼Œåªæœ‰ä¸¤â»”è¯¾é™¤å¤–â€”å—éžè¯­ï¼ˆæ¯•ä¸šé‚£å¹´çš„ç™¾åˆ†åˆ¶è€ƒè¯•ï¼Œä»–åªå¾—äº†61åˆ†ï¼‰å’Œå®—æ•™æ•™è‚²ï¼ˆâ½¼å¸ˆè¯´ä»–å¯¹äºŽæ•™è¯²â€œé—­ç›®å¡žå¬â€ï¼‰ã€‚ [190] [191]å¤§å­¦æ—¶æœŸçš„é©¬æ–¯å…‹1988å¹´ï¼Œé©¬æ–¯å…‹ä»Žæ¯”å‹’é™€åˆ©äºšç”·å­é«˜ä¸­æ¯•ä¸šåŽï¼Œç”±äºŽæ²¡æœ‰çˆ¶æ¯èµ„åŠ©åŠ ä¸Šä¹‰åŠ¡å…µå½¹çš„ç¼˜æ•…ï¼Œä»–é€‰æ‹©ç¦»å¼€å®¶åº­ã€‚ [3] [13]ã€‚1989å¹´ï¼ŒèŽ·å¾—åŠ æ‹¿å¤§å›½ç±åŽï¼Œåªèº«å‰å¾€åŠ æ‹¿å¤§ï¼Œå¯„å±…äºŽæ¯äº²äº²æˆšå®¶ä¸­ï¼Œå¹¶äºŽæ¬¡å¹´ç”³è¯·è¿›å…¥ä½äºŽå®‰å¤§ç•¥çœçš„å¥³çŽ‹å¤§å­¦ [4]ã€‚1992å¹´ï¼Œé©¬æ–¯å…‹ä¾é å¥–å­¦é‡‘è½¬å…¥ç¾Žå›½å®¾å¤•æ³•å°¼äºšå¤§å­¦æ²ƒé¡¿å•†å­¦é™¢æ”»è¯»ç»æµŽå­¦ï¼Œå¤§å­¦æœŸé—´ï¼Œä»–å¼€å§‹æ·±å…¥å…³æ³¨äº’è”ç½‘ã€æ¸…æ´èƒ½æºã€å¤ªç©ºè¿™ä¸‰ä¸ªå½±å“äººç±»æœªæ¥å‘å±•çš„é¢†åŸŸ [3]ã€‚åœ¨å–å¾—ç»æµŽå­¦å­¦å£«å­¦ä½åŽï¼Œåˆç•™æ ¡ä¸€å¹´æ‹¿åˆ°ç‰©ç†å­¦å­¦å£«å­¦ä½ã€‚ [4]1995å¹´ï¼Œé©¬æ–¯å…‹è¿›å…¥æ–¯å¦ç¦å¤§å­¦ï¼Œæ”»è¯»ææ–™ç§‘å­¦å’Œåº”ç”¨ç‰©ç† [14]åšå£«è¯¾ç¨‹ï¼Œä½†åœ¨å…¥å­¦åŽçš„ç¬¬2å¤©ï¼Œå°±å†³å®šç¦»å¼€å­¦æ ¡å¼€å§‹åˆ›ä¸šã€‚ [3]å·¥ä½œç»åŽ†æ’­æŠ¥ç¼–è¾‘åˆ›åŠžZip21995å¹´ï¼Œé©¬æ–¯å…‹è¾å­¦åŽï¼Œä¸Žå¼Ÿå¼Ÿå¡å§†å·´Â·é©¬æ–¯å…‹ï¼ˆKimbal Muskï¼‰æ‹¿åˆ°ç¡…è°·ä¸€ä¸ªå°é›†å›¢çš„éšæœºå¤©ä½¿æŠ•èµ„ [15]ï¼Œåˆ›åŠžäº†Zip2å…¬å¸ï¼Œè¿™æ˜¯ä¸€å®¶ä¸ºæ–°é—»æœºæž„å¼€å‘åœ¨çº¿å†…å®¹å‡ºç‰ˆè½¯ä»¶çš„å…¬å¸ï¼Œå½“æ—¶ã€Šçº½çº¦æ—¶æŠ¥ã€‹å’Œã€ŠèŠåŠ å“¥é‚®æŠ¥ã€‹éƒ½æˆä¸ºäº†é©¬æ–¯å…‹å…„å¼Ÿçš„å®¢æˆ·ã€‚å››å¹´åŽï¼Œç¾Žå›½ç”µè„‘åˆ¶é€ å•†åº·æŸå…¬å¸ä»¥3.07äº¿ç¾Žå…ƒçŽ°é‡‘å’Œ3400ä¸‡ç¾Žå…ƒè‚¡ç¥¨æœŸæƒæ”¶è´­äº†Zip2å…¬å¸ï¼Œ28å²çš„åŸƒéš†Â·é©¬æ–¯å…‹åœ¨è¿™ç¬”æ”¶è´­ä¸­èŽ·åˆ©2200ä¸‡ç¾Žå…ƒã€‚ [4]åˆ›åŠžX.com1999å¹´3æœˆï¼ŒåŸƒéš†Â·é©¬æ–¯å…‹æŠ•èµ„1000ä¸‡ç¾Žå…ƒï¼Œä¸Žä¸¤ä½æ¥è‡ªç¡…è°·çš„åˆä¼™äººåˆ›åŠžäº†ä¸€å®¶åœ¨çº¿é‡‘èžæœåŠ¡å’Œç”µå­é‚®ä»¶æ”¯ä»˜ä¸šåŠ¡å…¬å¸â€œX.comâ€ã€‚ [6]2000å¹´ï¼Œä¸ºè§£å†³åœ¨ç½‘ä¸Šå¿«æ·è½¬è´¦ä¸šåŠ¡ä¸Šçš„ç«žäº‰ï¼Œé©¬æ–¯å…‹å°†X.comå…¬å¸ä¸Žå½¼å¾—Â·è’‚å°”å’Œéº¦å…‹æ–¯Â·æ‹‰å¤«ç´åˆ›åŠžçš„Confinityå…¬å¸åˆå¹¶ã€‚2001å¹´ï¼Œæ–°å…¬å¸æ›´åä¸ºè´å®ï¼ˆPayPalï¼‰ã€‚2002å¹´åˆï¼ŒPayPalä¸Šå¸‚ [4]ã€‚2002å¹´10æœˆï¼ŒPayPalè¢«å½“æ—¶å…¨çƒæœ€å¤§çš„ç½‘å•†å…¬å¸æ˜“è´ï¼ˆeBayï¼‰ä»¥15äº¿ç¾Žå…ƒå…¨èµ„æ”¶è´­ï¼ŒåŸƒéš†Â·é©¬æ–¯å…‹ä½œä¸ºå½“æ—¶æ‹¥æœ‰è´å®11.7%è‚¡æƒçš„æœ€å¤§è‚¡ä¸œï¼Œæ‹¿åˆ°äº†1.65äº¿ç¾Žå…ƒã€‚ [4]åœ¨è¿™ç¬”äº¤æ˜“å®ŒæˆåŽï¼Œè´å®çš„è®¸å¤šæ ¸å¿ƒæˆå‘˜ç¦»å¼€äº†å…¬å¸ï¼Œé©¬æ–¯å…‹åœ¨å½¼å¾—Â·è’‚å°”ç¦»èŒåŽæŽ¥ä»»CEOä¸€èŒï¼Œä½†ä¹‹åŽå…¶åœ¨å…¬å¸å†…éƒ¨çš„æ–—äº‰ä¸­å¤±è´¥è€Œè¢«é€å‡ºå…¬å¸ã€‚ [16]åˆ›åŠžPayPalæ—¶æœŸçš„åŸƒéš†Â·é©¬æ–¯å…‹åˆ›åŠžSpaceXç«æ˜Ÿç»¿æ´²é©¬æ–¯å…‹åœ¨å¤§å­¦æ›¾ä¿®è¿‡ç‰©ç†å­¦ï¼Œä½†ä»–å¹¶ä¸æ˜¯ç«ç®­ä¸“å®¶ã€‚2001å¹´åˆï¼Œé©¬æ–¯å…‹è¿˜åœ¨è´å®æœŸé—´ï¼Œå°±ç­–åˆ’äº†ä¸€ä¸ªå«åšâ€œç«æ˜Ÿç»¿æ´²â€çš„é¡¹ç›®ï¼Œè®¡åˆ’æŠŠä¸€ä¸ªå°åž‹å®žéªŒæ¸©å®¤é™è½åœ¨ç«æ˜Ÿä¸Šï¼Œè®©æ¥è‡ªåœ°çƒçš„å†œä½œç‰©åœ¨ç«æ˜ŸåœŸå£¤é‡Œè¯•ç€ç”Ÿé•¿ã€‚ä¸è¿‡å½“ä»–å‘çŽ°åŽ»ä¿„ç½—æ–¯å®‡èˆªå…¬å¸è´­ä¹°è¿è½½ç«ç®­çš„æˆæœ¬å¤§å¤§é«˜å‡ºè‡ªè¡Œç ”å‘ç«ç®­çš„æˆæœ¬ï¼Œä¸”å‘å°„æˆæœ¬æ¯”è¿™ä¸ªé¡¹ç›®çš„ç ”å‘å’Œå·¥ç¨‹æˆæœ¬éƒ½è¦é«˜å¾—å¤šçš„æ—¶å€™ï¼Œæš‚ç¼“äº†è¿™ä¸ªé¡¹ç›®ï¼Œå†³å®šå…ˆæˆç«‹ä¸€ä¸ªå…¬å¸æ¥ç ”ç©¶æ€Žæ ·é™ä½Žå‘å°„æˆæœ¬ï¼Œè¿™å°±æ˜¯SpaceXå…¬å¸ã€‚ [4] [26]Space X2002å¹´6æœˆï¼Œé©¬æ–¯å…‹æŠ•èµ„1äº¿ç¾Žå…ƒæˆç«‹SpaceXï¼Œä»»é¦–å¸­æ‰§è¡Œå®˜å…¼é¦–å¸­æŠ€æœ¯å®˜ï¼Œå¼€å§‹ç ”ç©¶å¦‚ä½•é™ä½Žç«ç®­å‘å°„æˆæœ¬ï¼Œå¹¶è®¡åˆ’åœ¨æœªæ¥å®žçŽ°ç«æ˜Ÿç§»æ°‘ï¼Œæ‰“é€ äººç±»çœŸæ­£çš„å¤ªç©ºæ–‡æ˜Žã€‚ [17]çŒŽé¹°1å·2006å¹´3æœˆ24æ—¥ï¼ŒSpaceXçš„çŒŽé¹°1å·ç«ç®­ç¬¬ä¸€æ¬¡å‘å°„å¤±è´¥ï¼ŒåŽŸå› æ˜¯ä¸€æžšé“åˆ¶èžºæ “åœ¨å‘å°„å‰è¢«æµ·æ°´è…èš€åˆ°å‡ºçŽ°è£‚çº¹ï¼Œå¯¼è‡´ç¬¬ä¸€çº§ç«ç®­å‘å°„åŽç®¡é“æ¼æ²¹ç€ç«ï¼Œæ‘§æ¯äº†é©¬æ–¯å…‹æƒ³è¿…é€ŸæˆåŠŸå‘å°„çš„ç«ç®­æ¢¦ã€‚2007å¹´3æœˆ20æ—¥ï¼ŒSpaceXè¿Žæ¥äº†ç¬¬äºŒæ¬¡å‘å°„å¤±è´¥ï¼Œåœ¨æ­¤æ¬¡å‘å°„ä¸­ï¼Œç¬¬ä¸€çº§ç«ç®­å®Œæˆä½¿å‘½ï¼Œä¸€ã€äºŒçº§ç«ç®­æˆåŠŸåˆ†ç¦»ã€äºŒçº§å‘åŠ¨æœºé¡ºåˆ©ç‚¹ç«ã€å«æ˜Ÿæ•´æµç½©åˆ†ç¦»ï¼Œæœ€ç»ˆå› ä¸ºå°çš„åå·®å¯¼è‡´ç¬¬äºŒçº§ç«ç®­å¹¶æ²¡æœ‰èƒ½å¤ŸæˆåŠŸå…¥è½¨ã€‚2008å¹´8æœˆ2æ—¥ï¼ŒSpaceXç¬¬ä¸‰æ¬¡å‘å°„å¤±è´¥ï¼ŒåŽŸå› æ˜¯æ²¡æœ‰ä¸ºä¸€äºŒçº§ç«ç®­åˆ†ç¦»ç•™ä¸‹ä¸¤ä¸‰ç§’çš„è¶³å¤Ÿæ—¶é—´å·®ã€‚2008å¹´9æœˆ28æ—¥ï¼ŒSpaceXç¬¬å››æ¬¡å‘å°„çŒŽé¹°1å·ï¼Œæ­¤æ¬¡å‘å°„åœ¨é©¬ç»å°”ç¾¤å²›çš„æ¬§å§†é›·å…‹å²›ï¼ˆOmelek Islandï¼‰ä¸ŠèŽ·å¾—æˆåŠŸï¼Œè¿™æ˜¯ç§äººæŠ•èµ„å…¬å¸é¦–æ¬¡æˆåŠŸè¿›è¡Œè½¨é“å‘å°„ï¼Œä»£è¡¨ç€æ”¿åºœé¡¹ç›®ä¸»å¯¼çš„èˆªå¤©è¡Œä¸šå‘ç”Ÿäº†é‡å¤§è½¬å˜ã€‚åœ¨é¦–æ¬¡æˆåŠŸå‘å°„åŽï¼ŒSpaceXä»ŽNASAå’Œä¸€äº›ç§äººæŠ•èµ„è€…é‚£é‡ŒèŽ·å¾—äº†æ›´å¤šèµ„é‡‘ï¼Œå¼€å¯äº†é«˜é€Ÿå‘å±•ä¹‹è·¯ã€‚2009å¹´ï¼ŒçŒŽé¹°1å·ç«ç®­åœ¨ç¬¬äº”æ¬¡å‘å°„åŽé€€å½¹ã€‚ | [102] [122] [131] [153-154]ç¦å¸ƒæ–¯è´¢å¯Œæ¦œå•æ—¶é—´è´¢å¯ŒæŽ’å2024å¹´1950äº¿ç¾Žå…ƒ2024ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬2ä½ [165]2023å¹´1800äº¿ç¾Žå…ƒ2023ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬2ä½ [166]2022å¹´2190äº¿ç¾Žå…ƒ2022ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬1ä½ [68]2021å¹´1510äº¿ç¾Žå…ƒ2021ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬2ä½ [46]2020å¹´246äº¿ç¾Žå…ƒ2020ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬31ä½ [34]2019å¹´223äº¿ç¾Žå…ƒ2019ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬40ä½ [157]2018å¹´199äº¿ç¾Žå…ƒ2018ç¦å¸ƒæ–¯å…¨çƒäº¿ä¸‡å¯Œè±ªæ¦œç¬¬54ä½ [167]2017å¹´139äº¿ç¾Žå…ƒ2017å¹´ç¦å¸ƒæ–¯å…¨çƒå¯Œè±ªæŽ’è¡Œæ¦œç¬¬80ä½ [168]èƒ¡æ¶¦è´¢å¯Œæ¦œå•æ—¶é—´è´¢å¯ŒæŽ’å2024å¹´16700äº¿å…ƒäººæ°‘å¸2024èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬1ä½ [141]2023å¹´10500äº¿å…ƒäººæ°‘å¸2023èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬2ä½ [105]2022å¹´12900äº¿å…ƒäººæ°‘å¸2022å¹´èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬1ä½ [66]2021å¹´12800äº¿å…ƒäººæ°‘å¸2021èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬1ä½ [45]2020å¹´3220äº¿å…ƒäººæ°‘å¸2020èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬20ä½ [158]2019å¹´1900äº¿å…ƒäººæ°‘å¸2019èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬30ä½ [159]2018å¹´1500äº¿å…ƒäººæ°‘å¸2018èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬40ä½ [160]2017å¹´1000äº¿å…ƒäººæ°‘å¸2017èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬75ä½ [161]2016å¹´580äº¿å…ƒäººæ°‘å¸2016èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬134ä½ [163]2015å¹´390äº¿å…ƒäººæ°‘å¸2015èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬190ä½ [162]2014å¹´395äº¿å…ƒäººæ°‘å¸2014èƒ¡æ¶¦å…¨çƒå¯Œè±ªæ¦œç¬¬212ä½ [164]äººç‰©è¯„ä»·æ’­æŠ¥ç¼–è¾‘åŸƒéš†æœ‰ä¸€ç§éžå¸¸å¼ºçƒˆçš„ä¸“æ³¨æ¨¡å¼ï¼ˆintense modeï¼‰ï¼Œæˆ‘ä¹Ÿæœ‰è¿™æ ·çš„æ—¶å€™ã€‚æ‰€æœ‰æˆåŠŸè€…éƒ½æœ‰è¿™æ ·ä¸€é¢ã€‚ä»–ä»¬å¿…é¡»å¦‚æ­¤ï¼Œå¦åˆ™å°±ä¸ä¼šæˆåŠŸã€‚è¿™ç§æ¨¡å¼ä¼šè®©ä»–åªå…³æ³¨å¦‚ä½•å–å¾—æˆåŠŸï¼Œä¸åŠå…¶ä½™ã€‚è¿™ä¹Ÿå¯è¯´æ˜¯ä¸€ç§â€œèšç„¦â€ï¼Œå¿ƒç¥žæžåº¦é›†ä¸­ï¼Œå°±åƒæ”¾å¤§é•œå°†å…‰çº¿æ±‡èšäºŽçº¸ä¸Šä¸€ç‚¹ã€‚ï¼ˆé©¬æ–¯å…‹çš„çˆ¶äº²åŸƒç½—å°”Â·é©¬æ–¯å…‹ è¯„ï¼‰ [183]é©¬æ–¯å…‹ç”¨ä¸“æ³¨æ›¿ä»£äº†äº²å¯†ï¼Œè€Œä¸“æ³¨çš„å½“ç„¶æ˜¯äº‹ä¸šã€‚ï¼ˆé©¬æ–¯å…‹çš„ç¬¬ä¸€ä»»å¦»å­è´¾æ–¯æ±€Â·å¨å°”é€Š è¯„ï¼‰ [186]ä»–å†…å¿ƒä¾ç„¶æ˜¯ä¸ªç”·å­©ï¼Œä¸€ä¸ªç«™åœ¨çˆ¶äº²é¢å‰çš„å­©å­ã€‚ï¼ˆé©¬æ–¯å…‹çš„ç¬¬äºŒä»»å¦»å­å¦²éœ²æ‹‰Â·èŽ±èŽ‰ è¯„ï¼‰ [183]æˆ‘åªæ˜¯è§‰å¾—ä»–ä¸æ‡‚å¾—å¦‚ä½•äº«å—æˆåŠŸï¼Œå—…é—»èŠ±é¦™ã€‚ï¼ˆé©¬æ–¯å…‹å‰å¥³å‹æ ¼èŽ±å§†æ–¯ è¯„ï¼‰ [183]é©¬æ–¯å…‹æ˜¯ä¸€ä¸ªç›®æ ‡åšå®šã€ä»¥å·¥ç¨‹å¸ˆè§†è§’çœ‹ä¸–ç•Œçš„ç–¯ç‹‚åˆ›ä¸šè€…ï¼Œä»–åœ¨å¤§å­¦æ—¶æœŸå°±æ€è€ƒäººç±»æœªæ¥çš„å¤§é—®é¢˜ï¼Œå¹¶çœ‹å¥½äº’è”ç½‘ã€å¯æŒç»­èƒ½æºå’Œç©ºé—´æŽ¢ç´¢é¢†åŸŸï¼ŒåŽæ¥ä¹Ÿä¾æ¬¡å–å¾—äº†é‡å¤§æˆå°±ã€‚ä»–å¯¹äºŽåå¯¹è€…ä¼šåšå®šåå‡»ï¼Œè¡¨è¾¾è‡ªå·±çš„çœŸå®žæƒ³æ³•ã€‚ï¼ˆé©¬æ–¯å…‹åœ¨å®¾å¤•æ³•å°¼äºšå¤§å­¦çš„å®¤å‹Adeo Ressi è¯„ï¼‰ [7]åŸƒéš†Â·é©¬æ–¯å…‹æ˜¯å…¨ä¸–ç•Œçš„â€œä¼Ÿå¤§å¤©æ‰â€ä¹‹ä¸€ï¼Œä»–å°±åƒæ˜¯çˆ±è¿ªç”Ÿï¼Œä»–ä¹Ÿâ€œæ˜¯æˆ‘ä»¬ä¼Ÿå¤§çš„å¤©æ‰ä¹‹ä¸€ï¼Œè€Œæˆ‘ä»¬å¿…é¡»ä¿æŠ¤è‡ªå·±çš„å¤©æ‰â€ã€‚ï¼ˆæ—¶ä»»ç¾Žå›½æ€»ç»Ÿå”çº³å¾·Â·ç‰¹æœ—æ™® è¯„ï¼‰ [118] [128]åŸƒéš†æœ€äº†ä¸èµ·çš„ä¸€ç‚¹å°±æ˜¯èƒ½æŠŠè‡ªå·±çš„æ„¿æ™¯å½“ä½œä¸Šè‹çš„æ—¨æ„ã€‚ï¼ˆPaypalè”åˆåˆ›å§‹äººé©¬æ–¯å…‹Â·åˆ—å¤«ç´ è¯„ï¼‰ [183]é©¬æ–¯å…‹æ˜¯ä¸ºäº†å†’é™©è€Œå†’é™©ï¼Œä»–ä¼¼ä¹Žäº«å—å…¶ä¸­ï¼Œæœ‰æ—¶ç”šè‡³æ˜¯ä¸Šç˜¾ã€‚ä»–å¯¹é£Žé™©çš„ç†è§£æ˜¯æˆ‘ä»¬å¤§å¤šæ•°äººéƒ½ä¸å…·å¤‡çš„ã€‚ï¼ˆPaypalå…±åŒåˆ›å§‹äººå½¼å¾—Â·è’‚å°” è¯„ï¼‰ [183] [186]æ‹¥æŠ±é£Žé™©éœ€è¦èµŒæ€§ï¼Œè€Œé©¬æ–¯å…‹å±žäºŽé‚£ç§ä¹ æƒ¯äºŽå µä¸Šèº«å®¶æ€§å‘½ï¼Œè€Œä¸”ä¸æ„¿æ„ä¸‹åœºä¼‘æ¯çš„é‚£ç§ï¼Œä¹Ÿåªæœ‰è¿™ä¹ˆåšï¼Œæ‰èƒ½èŽ·å¾—ä¸€ç³»åˆ—çš„æˆåŠŸã€‚ï¼ˆé¢†è‹±åˆ›å§‹äººéœå¤«æ›¼ è¯„ï¼‰ [186]é©¬æ–¯å…‹æ˜¯ä¸€ä½éžå¸¸äº†ä¸èµ·çš„ä¼ä¸šå®¶ï¼Œè€Œç‰¹æ–¯æ‹‰æ˜¯ä¸€å®¶åœ¨æ±½è½¦å·¥ä¸šå²ä¸Šåˆ’æ—¶ä»£çš„ä¼Ÿå¤§çš„å…¬å¸ã€‚æˆ‘å’Œé©¬æ–¯å…‹ä¸€æ ·ï¼Œéƒ½å¸®åŠ©äº†ç§‘æŠ€çš„æ™®åŠï¼ŒæŽ¨åŠ¨äº†è¿™ä¸ªç¤¾ä¼šçš„è¿›æ­¥ã€‚ï¼ˆå°ç±³åˆ›å§‹äººé›·å†› è¯„ï¼‰ [184]æœ‰ä¸€ç§äººï¼Œæ™ºå•†è¾¾åˆ°190ï¼Œä½†æ˜¯ä»–ä»¬ä»¥ä¸ºè‡ªå·±çš„æ™ºå•†æœ‰250ã€‚è¿™ç§äººï¼Œæˆ‘æœ€æ€•äº†ï¼Œé©¬æ–¯å…‹æœ‰ç‚¹ç±»ä¼¼è¿™ç§äººã€‚ï¼ˆæŠ•èµ„å®¶æŸ¥ç†Â·èŠ’æ ¼ è¯„ï¼‰ [186]é©¬æ–¯å…‹ä¸“æ¨ªã€æƒ…ç»ªåŒ–ã€çˆ±é¢å­ã€ç¼ºä¹å®‰å…¨æ„Ÿã€è‡ªå¤§ã€åæ‰§ï¼Œæ˜¯ä¸€ä¸ªå¾ˆéš¾ç›¸å¤„çš„äººã€‚ä¼¼ä¹Žç¦»å¼€ç‰¹æ–¯æ‹‰çš„äººï¼Œæ²¡æœ‰æƒ³å†å›žåŽ»çš„ã€‚é©¬æ–¯å…‹å¾ˆéš¾ç•Œå®šæ˜¯åäººï¼Œè¿˜æ˜¯è‹±é›„ã€‚ä»–èº«ä¸Šæœ‰å¾ˆå¤šç°è‰²åœ°å¸¦ï¼Œå¾ˆå¤šæ—¶å€™å–å†³äºŽä»–å½“å¤©çš„å¿ƒæƒ…ã€‚ä»–æ‹¥æœ‰ä¸€ç§ç½•è§çš„èƒ½åŠ›ï¼Œå°±æ˜¯å«æŽ¥å·¥ç¨‹å¸ˆå’Œé”€å”®äººå‘˜çš„èƒ½åŠ›ã€‚æ—¢èƒ½è·Ÿå·¥ç¨‹å¸ˆæ²Ÿé€šæŠ€æœ¯é—®é¢˜ï¼Œä¹Ÿèƒ½å‘å¤–ç•Œå±•ç¤ºå’Œè¥é”€ç”µåŠ¨æ±½è½¦ã€‚èƒ½æŽ¨åŠ¨å°–ç«¯ç§‘æŠ€å‘å±•ï¼Œä¹Ÿèƒ½æŠŠå°–ç«¯ç§‘æŠ€åˆ†äº«ç»™æ™®ç½—å¤§ä¼—ã€‚ï¼ˆç¾Žå›½èµ„æ·±è´¢ç»è¯„è®ºå‘˜ã€ã€ŠåŽå°”è¡—æ—¥æŠ¥ã€‹ç§‘æŠ€ä¸Žæ±½è½¦ä¸“æ è®°è€…æå§†Â·å¸Œé‡‘æ–¯ è¯„ï¼‰ [185]äººç‰©äº‹ä»¶æ’­æŠ¥ç¼–è¾‘é˜»ç¢ç§‘æŠ€åˆ›æ–°å¥–2016å¹´ï¼Œé©¬æ–¯å…‹å› ä¸ºå¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æ€åº¦è€ŒèŽ·å¾—äº†â€œé˜»ç¢æŠ€æœ¯åˆ›æ–°â€å¥–ï¼Œå³â€œå¢å¾·å¥–â€ã€‚ä»–å’Œå²è’‚èŠ¬Â·éœé‡‘ç­‰äººå› ä¸ºå¯¹äººå·¥æ™ºèƒ½ä¿æŒé«˜åº¦è­¦æƒ•ï¼Œå¹¶è¡¨è¾¾äº†å¯¹æ­¤æŠ€æœ¯çš„æ‹…å¿§ï¼Œè€Œè¢«è®¤ä¸ºåœ¨ä¸€å®šç¨‹åº¦ä¸Šé˜»ç¢æŠ€æœ¯åˆ›æ–°ã€‚ä»–ä»¬æ‹…å¿ƒäººå·¥æ™ºèƒ½çš„å‘å±•å¯èƒ½è¶…å‡ºäººç±»æŽ§åˆ¶ï¼Œå¹¶å‘¼åå¯¹è‡ªåŠ¨åŒ–æ­¦å™¨ç­‰æŠ€æœ¯è¿›è¡Œé™åˆ¶ã€‚ | äº¬ICPè¯030173å· äº¬å…¬ç½‘å®‰å¤‡11000002000001å·
----------------------

Query: é©¬æ–¯å…‹åœ¨2001å¹´åˆåšäº†ä»€ä¹ˆ
Answer:
# ç¬¬ä¸€ä¸ªç¤ºä¾‹çš„ç»“æžœ
åœ¨2001å¹´åˆï¼Œé©¬æ–¯å…‹è¿˜åœ¨è´å®æœŸé—´ï¼Œç­–åˆ’äº†ä¸€ä¸ªåä¸ºâ€œç«æ˜Ÿç»¿æ´²â€çš„é¡¹ç›®ï¼Œè®¡åˆ’å°†ä¸€ä¸ªå°åž‹å®žéªŒæ¸©å®¤é™è½åœ¨ç«æ˜Ÿä¸Šï¼Œä»¥å°è¯•è®©åœ°çƒçš„å†œä½œç‰©åœ¨ç«æ˜ŸåœŸå£¤ä¸­ç”Ÿé•¿ã€‚ç„¶è€Œï¼Œå½“ä»–å‘çŽ°è´­ä¹°ä¿„ç½—æ–¯å®‡èˆªå…¬å¸è¿è½½ç«ç®­çš„æˆæœ¬è¿œé«˜äºŽè‡ªè¡Œç ”å‘ç«ç®­çš„æˆæœ¬ï¼Œä¸”å‘å°„æˆæœ¬æ¯”é¡¹ç›®çš„ç ”å‘å’Œå·¥ç¨‹æˆæœ¬è¿˜è¦é«˜æ—¶ï¼Œä»–å†³å®šæš‚ç¼“è¿™ä¸ªé¡¹ç›®ï¼Œå¹¶æˆç«‹SpaceXå…¬å¸ï¼Œä»¥ç ”ç©¶å¦‚ä½•é™ä½Žå‘å°„æˆæœ¬ã€‚
# ç¬¬äºŒä¸ªç¤ºä¾‹çš„user prompt
You are a Q&A expert system. Your responses must always be rooted in the context provided for each query. Here are some guidelines to follow:

1. Refrain from explicitly mentioning the context provided in your response.
2. The context should silently guide your answers without being directly acknowledged.
3. Do not use phrases such as 'According to the context provided', 'Based on the context, ...' etc.

Context information:
----------------------
[192-195]çŒŽé¹°9å·åŸƒéš†Â·é©¬æ–¯å…‹ä¸ŽçŒŽé¹°è¿è½½ç«ç®­çŒŽé¹°1å·å‘å°„æˆåŠŸä¹‹åŽï¼ŒSpaceXå°±å¼€å§‹å‡çº§ï¼Œå°†åŽŸæœ¬ä»…æœ‰1å°æ¢…æž—ï¼ˆMerlinï¼‰å‘åŠ¨æœºçš„çŒŽé¹°1å·å‡çº§ä¸ºç”±9å°æ¢…æž—å‘åŠ¨æœºç»„æˆçš„çŒŽé¹°9å·ã€‚2010å¹´6æœˆ4æ—¥çŒŽé¹°9å·å®Œæˆé¦–æ¬¡å‘å°„ï¼Œ2011å¹´SpaceXåˆæ‹¿åˆ°è¿½åŠ è‡³3.96äº¿ç¾Žå…ƒçš„æŠ•èµ„ï¼Œç”¨äºŽç ”å‘çŒŽé¹°9å·å’Œé¾™é£žèˆ¹ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œç«ç®­å‘å°„å‡ç©ºåŽï¼Œç¬¬ä¸€çº§æŽ¨è¿›å™¨å°±ä¼šè¢«åºŸå¼ƒï¼Œé©¬æ–¯å…‹è®¤ä¸ºè¿™æ˜¯ç«ç®­å‘å°„æˆæœ¬é«˜çš„ä¸»è¦åŽŸå› ï¼Œè‹¥èƒ½å°†å…¶å›žæ”¶å°†æœ‰æ•ˆé™ä½Žæˆæœ¬ã€‚ä»Ž2012å¹´9æœˆåˆ°2013å¹´10æœˆï¼ŒSpaceXé™†ç»­åšäº†8æ¬¡ç«ç®­å›žæ”¶è¯•éªŒï¼Œæœ€ç»ˆåœ¨2015å¹´12æœˆ21æ—¥ï¼ŒçŒŽé¹°9å·å®‰å…¨åœ¨é™†åœ°è½¯ç€é™†ï¼Œè¿™ä¹Ÿæ˜¯äººç±»å‘å°„ç«ç®­åŽ†å²ä¸Šçš„ç¬¬ä¸€æ¬¡åŠ©æŽ¨å™¨å›žæ”¶ã€‚2016å¹´4æœˆï¼ŒçŒŽé¹°9å·æ­è½½é¾™é£žèˆ¹é¡ºåˆ©å‡ç©ºï¼Œä¸€çº§ç«ç®­åŠ©æŽ¨å™¨åˆ†ç¦»ä¹‹åŽï¼Œç¨³ç¨³é™è½åœ¨æµ·ä¸Šå›žæ”¶å¹³å°ï¼Œå®žçŽ°äº†é¦–æ¬¡æµ·ä¸Šå›žæ”¶ã€‚2016å¹´ï¼ŒSpaceXç»åŽ†äº†è¢«é©¬æ–¯å…‹ç§°ä¸ºâ€œæœ€å›°éš¾æœ€å¤æ‚â€çš„ä¸€æ¬¡å¤±è´¥ã€‚å½“å¹´9æœˆ1æ—¥ï¼ŒçŒŽé¹°9å·åœ¨å‘å°„å‰çš„æµ‹è¯•ä¸­çˆ†ç‚¸äº†ï¼Œäº‹æ•…é€ æˆFacebookä»·å€¼2äº¿ç¾Žå…ƒçš„Amos-6å«æ˜Ÿå®Œå…¨æ‘§æ¯ï¼ŒSpaceXä¹Ÿç”±æ­¤é™·å…¥äº†4ä¸ªæœˆçš„åœæ»žï¼Œç›´è‡³æ¬¡å¹´1æœˆæ‰é‡æ–°å¼€å§‹å‘å°„è¯•éªŒã€‚åœ¨æ— æ•°æ¬¡çš„çˆ†ç‚¸å’Œå¤±è´¥ä¸­ï¼ŒçŒŽé¹°9å·é€æ¸æˆä¸ºSpaceXæœ€ä¸ºæˆç†Ÿçš„ç«ç®­ï¼Œæ‹…è´Ÿäº†SpaceXçš„ä¸»è¦å‘å°„ä»»åŠ¡ã€‚ [195]é‡åž‹çŒŽé¹°2011å¹´ï¼ŒSpaceXæ——ä¸‹çš„å¤§è¿åŠ›ç«ç®­â€œé‡åž‹çŒŽé¹°â€ï¼ˆFalcon Heavyï¼‰é¦–æ¬¡å¯¹å¤–äº®ç›¸ï¼Œâ€œé‡åž‹çŒŽé¹°â€é«˜69.2ç±³ï¼Œè¿‘åœ°è½¨é“è½½è·è¾¾63.8å¨ï¼Œé‡‡ç”¨èŠ¯çº§å¹¶è”çš„ç»“æž„è®¾è®¡ï¼Œç”±ä¸‰æžšç»æ”¹è£…çš„â€œçŒŽé¹°9å·â€ç«ç®­ç»„è£…è€Œæˆã€‚2015å¹´å’Œ2016å¹´çš„ä¸€äº›ç«ç®­æ•…éšœè¿«ä½¿å…¬å¸æŽ¨è¿Ÿå‘å°„ã€‚åœ¨è¿‡åŽ»å‡ å¹´ä¸­ï¼ŒSpaceXä¸€ç›´åœ¨æ›´æ–°ç«ç®­çš„ç›®æ ‡å‘å°„æ—¥æœŸï¼›åˆ°äº†2017å¹´å¹´åº•ï¼Œåˆå› ä¸ºç¾Žå›½æ”¿åºœåœæ‘†ï¼Œé©¬æ–¯å…‹æš‚åœäº†å‘å°„ã€‚ç›´è‡³2018å¹´ä¼Šå§‹ï¼ŒSpaceXæ‰é¦–æ¬¡å…¬å¸ƒä¸€ä¸ªå…·ä½“å‘å°„æ—¥æœŸã€‚ [196]2018å¹´2æœˆ7æ—¥ï¼Œâ€œé‡åž‹çŒŽé¹°â€è¿è½½ç«ç®­åœ¨ç¾Žå›½è‚¯å°¼è¿ªèˆªå¤©ä¸­å¿ƒé¦–æ¬¡æˆåŠŸå‘å°„ï¼Œå¹¶æˆåŠŸå®Œæˆä¸¤æžšä¸€çº§åŠ©æŽ¨ç«ç®­çš„å®Œæ•´å›žæ”¶ã€‚ [8]é¾™é£žèˆ¹é©¬æ–¯å…‹åœ¨SPACEXå‰ç•™å½±2012å¹´10æœˆ7æ—¥ï¼ŒSpaceXä»Žå¡çº³ç»´æ‹‰å°”è§’ç©ºå†›åŸºåœ°å‘å°„äº†çŒŽé¹°9å·ç«ç®­ï¼Œå°†é¾™é£žèˆ¹é€å…¥è½¨é“ï¼Œè¿™æ˜¯SpaceXå…¬å¸è´§è¿é£žèˆ¹é¦–æ¬¡æ­£å¼æ‰¿æ‹…å‘å›½é™…å¤ªç©ºç«™è¿è´§çš„ä»»åŠ¡ [197]ï¼Œä¹Ÿæ˜¯ç¬¬ä¸€è‰˜å‘å›½é™…ç©ºé—´ç«™è¿é€è´§ç‰©çš„å•†ä¸šé£žèˆ¹ï¼Œå¹¶ä¿ƒä½¿NASAå’ŒSpaceXåˆç­¾è®¢äº†å‡ ä»½åˆåŒã€‚é¾™é£žèˆ¹1å·åœ¨2020å¹´é€€å½¹ï¼Œä¹‹å‰å‘å›½é™…ç©ºé—´ç«™æ‰§è¡Œäº†23æ¬¡è´§è¿ä»»åŠ¡ã€‚SpaceXå…¬å¸ä»Ž2014å¹´å¼€å§‹ç ”å‘é¾™é£žèˆ¹2å·ï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿæ­è½½å®‡èˆªå‘˜å’Œè´§ç‰©çš„ç‰ˆæœ¬ã€‚2020å¹´5æœˆ30æ—¥ï¼ŒSpaceXä½¿ç”¨çŒŽé¹°9å·å‘å°„äº†æ–°çš„è½½äººé¾™é£žèˆ¹ï¼Œä¸Šé¢æ­è½½ä¸¤åå®‡èˆªå‘˜é“æ ¼Â·èµ«å°”åˆ©ï¼ˆDoug Hurleyï¼‰å’Œé²å‹ƒÂ·æœ¬è‚¯ï¼ˆBob Behnkenï¼‰ã€‚è¿™ä¸¤äººæ˜¯ç¬¬ä¸€æ‰¹ä¹˜åSpaceXç«ç®­å‡ç©ºçš„äººç±»ã€‚ [193]2021å¹´4æœˆ23æ—¥ï¼Œè½½æœ‰4åå®‡èˆªå‘˜çš„SpaceXé¾™é£žèˆ¹åœ¨è‚¯å°¼è¿ªèˆªå¤©ä¸­å¿ƒå‘å°„å‡ç©ºï¼Œé£žèˆ¹é£žå¾€å›½é™…ç©ºé—´ç«™ï¼Œæ­¤æ¬¡è½½äººé£žè¡Œä»»åŠ¡ä¹Ÿæ˜¯SpaceXä¸Žç¾Žå›½å›½å®¶èˆªç©ºèˆªå¤©å±€è¿›è¡Œçš„ç¬¬äºŒæ¬¡å•†ä¸šè½½äººèˆªå¤©å‘å°„ä»»åŠ¡ã€‚ [198]2021å¹´9æœˆ15æ—¥ï¼Œäº¿ä¸‡å¯Œç¿è´¾é‡Œå¾·Â·ä¼Šè¨å…‹æ›¼ï¼ˆJared Issacmanï¼‰å’Œå…¶ä»–ä¸‰åä¹˜å®¢åŒ…ä¸‹SpaceXçš„ä¸€æ¬¡ç§äººèˆªå¤©æ—…è¡Œï¼Œåœ¨å¤ªç©ºä¸­åº¦è¿‡äº†ä¸‰å¤©ï¼ŒSpaceXä½¿ç”¨çŒŽé¹°9å·å°†ä»–ä»¬é€å…¥å¤ªç©ºï¼Œä¹˜åçš„æ˜¯â€œåšéŸ§å·â€è½½äººé¾™é£žèˆ¹ï¼Œè¿™æ¬¡å¤ªç©ºé£žè¡Œæ˜¯ç¬¬ä¸€æ¬¡æ²¡æœ‰ä»»ä½•ä¸“ä¸šå®‡èˆªå‘˜çš„æƒ…å†µä¸‹åˆ°è¾¾è½¨é“çš„è½½äººé£žè¡Œä»»åŠ¡ã€‚ [193]æ˜Ÿé™…é£žèˆ¹Starship2019å¹´åº•ï¼Œ SpaceXå¼€å§‹ç ”å‘æ–°é¡¹ç›®ï¼Œç€æ‰‹å»ºé€ ä¸‹ä¸€ä»£æ˜Ÿé™…é£žèˆ¹Starshipã€‚Starshipé£žèˆ¹é•¿50ç±³ï¼Œç›´å¾„9ç±³ï¼Œç”±åˆé‡‘é’¢åˆ¶æˆï¼Œå‘å°„è½½è·ä¸º150å¨ï¼Œå¯é‡å¤ä½¿ç”¨ï¼Œç”¨äºŽç«æ˜Ÿé£žè¡Œï¼Œå¯å®¹çº³100äººã€‚ [195]2021å¹´5æœˆï¼ŒSpaceXé¦–æ¬¡åœ¨æ²¡æœ‰å‘ç”Ÿçˆ†ç‚¸çš„æƒ…å†µä¸‹å®Œæˆäº†Starshipçš„äºšè½¨é“è¯•é£žï¼Œæ­¤å‰å››æ¬¡ï¼ŒStarshipåŽŸåž‹éƒ½å‘ç”Ÿäº†çˆ†ç‚¸ã€‚é©¬æ–¯å…‹çš„é•¿æœŸç›®æ ‡æ˜¯åœ¨ç«æ˜Ÿä¸Šå»ºé€ è‡ªç»™è‡ªè¶³çš„å®šå±…ç‚¹ï¼Œä¸ºäº†å°†è¶³å¤Ÿçš„äººå‘˜å’Œç‰©èµ„é€å¾€è¿™é¢—çº¢è‰²æ˜Ÿçƒï¼ŒSpaceXéœ€è¦ä¸€æžšå¼ºå¤§ä¸”å®Œå…¨å¯é‡å¤ä½¿ç”¨çš„ç«ç®­ï¼ŒäºŽæ˜¯ï¼ŒStarshipå’Œè¶…é‡åž‹çŒŽé¹°ç«ç®­çš„ç»„åˆä½“ç™»åœºã€‚ [193]æ˜Ÿé“¾ç½‘ç»œ2015å¹´1æœˆï¼Œé©¬æ–¯å…‹å®£å¸ƒSpaceXçš„å«æ˜Ÿäº’è”ç½‘æœåŠ¡çš„è®¡åˆ’ã€‚SpaceXè®¡åˆ’å°†çº¦1.2ä¸‡é¢—é€šä¿¡å«æ˜Ÿå‘å°„åˆ°è½¨é“ï¼Œå¹¶ä»Ž2020å¹´å¼€å§‹å·¥ä½œï¼Œè¿™ä¸€é¡¹ç›®è¢«å‘½åä¸ºâ€œæ˜Ÿé“¾â€ï¼ˆStarlinkï¼‰ï¼Œæ„å›¾åœ¨å…¨çƒèŒƒå›´å†…æä¾›ä½Žæˆæœ¬çš„äº’è”ç½‘è¿žæŽ¥æœåŠ¡ã€‚ [200]2018å¹´3æœˆï¼ŒçŒŽé¹°9å·ç«ç®­åœ¨ä¸€æ¬¡å¸¸è§„å‘å°„ä»»åŠ¡ä¸­æ­è½½äº†2é¢—å°å«æ˜Ÿâ€”â€œä¸ä¸-aâ€å’Œâ€œä¸ä¸-bâ€ï¼Œå®ƒä»¬æ˜¯SpaceXæ˜Ÿé“¾è®¡åˆ’çš„è¯•éªŒæ˜Ÿï¼Œä¸»è¦å¼€å±•å¯¹åœ°é€šä¿¡æµ‹è¯• [201]ã€‚2019å¹´ï¼ŒSpaceXå¼€å§‹å‘å°„æ˜Ÿé“¾å«æ˜Ÿ | [193]ã€‚2020å¹´5æœˆï¼ŒSpaceXå‘ç¾Žå›½è”é‚¦é€šä¿¡å§”å‘˜ä¼šæäº¤ç¬¬äºŒä»£â€œæ˜Ÿé“¾â€å«æ˜Ÿéƒ¨ç½²è®¡åˆ’ç”³è¯·ï¼Œå¸Œæœ›é¢å¤–éƒ¨ç½²3ä¸‡é¢—å«æ˜Ÿï¼Œå°†â€œæ˜Ÿé“¾â€å«æ˜Ÿæ•°é‡æ‰©å……è‡³4.2ä¸‡é¢—ã€‚2022å¹´12æœˆï¼Œç¾Žå›½è”é‚¦é€šä¿¡å§”å‘˜ä¼šæ‰¹å‡†â€œæ˜Ÿé“¾â€é¡¹ç›®éƒ¨ç½²è‡³å¤š7500é¢—ç¬¬äºŒä»£å«æ˜Ÿï¼Œå…¶ä½™æš‚ç¼“å†³å®šï¼Œä»¥å›žåº”â€œæœ‰å…³è½¨é“ç¢Žç‰‡å’Œèˆªå¤©å®‰å…¨çš„æ‹…å¿§â€ã€‚ [202]æˆªè‡³2024å¹´4æœˆï¼Œè¯¥å…¬å¸å·²ç»å‘è¿‘åœ°è½¨é“å‘å°„äº†6145é¢—æ˜Ÿé“¾å«æ˜Ÿã€‚ [199]æŠ•èµ„ç‰¹æ–¯æ‹‰2004å¹´ï¼Œé©¬æ–¯å…‹å‘é©¬ä¸Â·è‰¾ä¼¯å“ˆå¾·åˆ›ç«‹çš„ç”µåŠ¨æ±½è½¦åˆ¶é€ å•†ç‰¹æ–¯æ‹‰æ±½è½¦æŠ•èµ„630ä¸‡ç¾Žå…ƒï¼Œæ¡ä»¶æ˜¯ä»–å‡ºä»»è¯¥å…¬å¸çš„è‘£äº‹é•¿ï¼Œå¹¶æ‹¥æœ‰æ‰€æœ‰äº‹åŠ¡çš„æœ€ç»ˆå†³å®šæƒã€‚ [4] [6]2008å¹´ï¼Œç‰¹æ–¯æ‹‰æŽ¨å‡ºç¬¬ä¸€æ¬¾ç”µåŠ¨è·‘è½¦Roadsterï¼Œä½†å› ä¸ºé‡‘èžå±æœºè”“å»¶ï¼Œç‰¹æ–¯æ‹‰é«˜æ˜‚çš„ç ”å‘æˆæœ¬ï¼Œä¸€åº¦è®©å…¬å¸é™·å…¥å›°å¢ƒï¼Œé¢ä¸´ç ´äº§é£Žé™© [203]ã€‚ä¸ºäº†è§£å†³èµ„é‡‘çŸ­ç¼ºï¼Œé©¬æ–¯å…‹æŠŠä»–ä¸ªäººæœ€åŽçš„4000ä¸‡ç¾Žå…ƒæŠ•äº†è¿›åŽ»ï¼Œå¹¶æ‹…ä»»ç‰¹æ–¯æ‹‰CEOï¼Œå¸¦é¢†ç‰¹æ–¯æ‹‰æŒºè¿‡æœ€è‰°éš¾çš„æ—¶åˆ»ã€‚2010å¹´åˆï¼Œæ—¶ä»»ç¾Žå›½æ€»ç»Ÿå¥¥å·´é©¬å‚è§‚ç‰¹æ–¯æ‹‰å·¥åŽ‚ï¼ŒéšåŽç‰¹æ–¯æ‹‰æˆåŠŸæ‹¿ä¸‹4.65äº¿ç¾Žå…ƒçš„æ”¿åºœä½Žæ¯è´·æ¬¾ï¼Œä¹‹åŽModel Så¼€å§‹æŽ¥å—é¢„å®š [204]ã€‚2010å¹´6æœˆï¼Œé©¬æ–¯å…‹æˆåŠŸå¸¦é¢†ç‰¹æ–¯æ‹‰åœ¨çº³æ–¯è¾¾å…‹ä¸Šå¸‚ï¼Œç­¹é›†äº†çº¦1.84äº¿ç¾Žå…ƒèµ„é‡‘ã€‚å°½ç®¡ä¸Šå¸‚å‰å¤•æœ‰æŠ¥é“ç§°ä»–æ¿’ä¸´ä¸ªäººç ´äº§ï¼Œä½†ç‰¹æ–¯æ‹‰æˆåŠŸä¸Šå¸‚ä¸ºä»–å¸¦æ¥äº†è½¬æœºã€‚ä¸Šå¸‚åŽï¼Œé©¬æ–¯å…‹çš„ä¸ªäººè´¢å¯Œå¤§å¹…å¢žé•¿ï¼Œç‰¹æ–¯æ‹‰ä¹Ÿæˆä¸ºè‡ª1956å¹´ç¦ç‰¹æ±½è½¦IPOä»¥æ¥ï¼Œç¬¬ä¸€å®¶ä¸Šå¸‚çš„ç¾Žå›½æ±½è½¦åˆ¶é€ å•†ï¼Œå¹¶ä¸”æ˜¯å½“æ—¶å”¯ä¸€ä¸€å®¶åœ¨ç¾Žå›½ä¸Šå¸‚çš„çº¯ç”µåŠ¨æ±½è½¦ç‹¬ç«‹åˆ¶é€ å•†ã€‚ [18]é©¬æ–¯å…‹ä¸Žç‰¹æ–¯æ‹‰2012å¹´ï¼Œç‰¹æ–¯æ‹‰æ­£å¼æŽ¨å‡ºäº†Model Sã€‚éšç€è¿™ä¸€è½¦åž‹çš„æˆåŠŸï¼Œç‰¹æ–¯æ‹‰è‚¡ä»·ä¸æ–­ä¸Šæ¶¨ï¼Œåœ¨2013å¹´å†²ä¸Šäº†æ¯è‚¡158ç¾Žå…ƒçš„åŽ†å²é«˜ç‚¹ï¼ŒåŒå¹´7æœˆï¼Œç‰¹æ–¯æ‹‰è¢«çº³å…¥çº³æ–¯è¾¾å…‹100æŒ‡æ•°ï¼Œæˆä¸ºå”¯ä¸€è¿›å…¥è¿™ä¸€æŒ‡æ•°çš„ç¾Žå›½æ±½è½¦è‚¡ï¼Œå¸‚å€¼å¾ˆå¿«è¶…è¿‡100äº¿ç¾Žå…ƒã€‚ [205]2014å¹´ï¼Œç‰¹æ–¯æ‹‰å®£å¸ƒå…±äº«ä¸“åˆ©æŠ€æœ¯ï¼ŒæŽ¨åŠ¨ç”µåŠ¨è½¦å‘å±•ï¼Œå…¶å¼€æ”¾ä¸“åˆ©çš„è¡Œä¸ºè¢«è§†ä¸ºæ„å›¾æˆä¸ºè¡Œä¸šæ ‡å‡† [212-213]ã€‚éšç€ç‰¹æ–¯æ‹‰å…¨çƒå·¥åŽ‚ä¸æ–­å»ºç«‹ï¼Œ2019å¹´ï¼Œç‰¹æ–¯æ‹‰ä¸Šæµ·è¶…çº§å·¥åŽ‚ä»¥â€œç‰¹æ–¯æ‹‰â€é€Ÿåº¦ï¼Œå®žçŽ°å¼€å·¥ã€æŠ•äº§ã€äº¤ä»˜ä¸‰æ­¥èµ°ï¼Œæˆä¸ºä¸­å›½ç¬¬ä¸€å®¶å¤–å•†ç‹¬èµ„è®¾ç«‹çš„æ±½è½¦å…¬å¸ï¼Œä¹Ÿæ˜¯ç‰¹æ–¯æ‹‰é¦–ä¸ªæµ·å¤–å·¥åŽ‚ã€‚ [206]2020å¹´6æœˆ10å·ï¼Œç‰¹æ–¯æ‹‰è‚¡ä»·é¦–ç ´1000ç¾Žå…ƒï¼Œæˆä¸ºå…¨çƒå¸‚å€¼æœ€é«˜è½¦ä¼ [207]ã€‚ç‰¹æ–¯æ‹‰å…¬å¸é€æ¸å½¢æˆäº†Model Sï¼ŒModel Xï¼ŒModel Yï¼ŒModel 3ç­‰æ–°èƒ½æºè½¦é˜µè¥ï¼Œæ­¤å¤–è¿˜ç ”å‘é”€å”®å¤ªé˜³èƒ½ç”µæ± æ¿ï¼Œå¤ªé˜³èƒ½å±‹é¡¶ç­‰æ¸…æ´èƒ½æºäº§å“ã€‚ [209]åˆ›åŠžSolarCityé©¬æ–¯å…‹æ——ä¸‹ä¸‰å¤§é‡è¦å…¬å¸2006å¹´ï¼Œé©¬æ–¯å…‹ä¸ªäººå‡ºèµ„1000ä¸‡ç¾Žå…ƒï¼Œåˆ›åŠžäº†å¤ªé˜³åŸŽå…¬å¸ï¼ˆSolarCityï¼‰ï¼Œç”±ä»–çš„è¡¨å¼ŸLyndon Riveæ‹…ä»»CEOå’Œè”åˆåˆ›å§‹äººã€‚å…¶ç›®æ ‡æ˜¯è®©åƒå®¶ä¸‡æˆ·ä½¿ç”¨å¤ªé˜³èƒ½å‘ç”µç³»ç»Ÿï¼Œâ€œåŠ é€Ÿå¯æŒç»­èƒ½æºæ—¶ä»£çš„åˆ°æ¥â€ã€‚2016å¹´1æœˆï¼ŒSolarCityå·²å‘å±•ä¸ºç¾Žå›½å¤ªé˜³èƒ½å‘ç”µç³»ç»Ÿä¾›åº”å•†é¾™å¤´ï¼Œåœ¨åŠ å·žã€äºšåˆ©æ¡‘é‚£å·žå’Œä¿„å‹’å†ˆå·žçš„500ä¸ªç¤¾åŒºæä¾›æœåŠ¡ã€‚ [4]2016å¹´8æœˆï¼Œç‰¹æ–¯æ‹‰å…¬å¸å®£å¸ƒï¼Œä¸Žå¤ªé˜³åŸŽå…¬å¸è¾¾æˆä¸€é¡¹ä»·å€¼26äº¿ç¾Žå…ƒçš„å¹¶è´­åè®®ï¼Œè¿™é¡¹äº¤æ˜“è¢«åª’ä½“å½¢å®¹ä¸ºâ€œå·¦æ‰‹ç‰µå³æ‰‹â€ï¼Œå› ä¸ºå¤ªé˜³åŸŽå…¬å¸è‘£äº‹ä¼šä¸»å¸­åŠæŽ§è‚¡è‚¡ä¸œæ­£æ˜¯ç‰¹æ–¯æ‹‰é¦–å¸­æ‰§è¡Œå®˜åŸƒéš†Â·é©¬æ–¯å…‹ã€‚é©¬æ–¯å…‹è¡¨ç¤ºï¼Œè¿™é¡¹äº¤æ˜“å°†åŠ é€Ÿç‰¹æ–¯æ‹‰ä»Žç”µåŠ¨æ±½è½¦åˆ¶é€ å•†å‘ä¸€ä½“åŒ–å¯å†ç”Ÿèƒ½æºå…¬å¸çš„è½¬å˜ã€‚ç‰¹æ–¯æ‹‰ä¸Žå¤ªé˜³åŸŽçš„æ•´åˆï¼Œå°†æ”¹å˜èƒ½æºç”Ÿäº§ã€å­˜å‚¨å’Œæ¶ˆè´¹æ¨¡å¼ï¼Œå…¶æœ€ç»ˆç›®æ ‡æ˜¯æ‰“é€ å…¨çƒå”¯ä¸€çš„åž‚ç›´ä¸€ä½“åŒ–èƒ½æºå…¬å¸ï¼Œäº§å“è¦†ç›–å¤ªé˜³èƒ½é¢æ¿ã€å®¶ç”¨è“„ç”µæ± å’Œç”µåŠ¨è½¦ç­‰ã€‚ [208]åˆ›åŠžè½¨äº¤å…¬å¸2016å¹´12æœˆï¼Œé©¬æ–¯å…‹æˆç«‹äº†ä¸€å®¶è§£å†³åœ°é¢æ‹¥å µé—®é¢˜çš„è½¨é“äº¤é€šå…¬å¸The Boring Company [19]ï¼Œæ ¹æ®å…¶è®¾æƒ³ï¼Œä»–å°†åœ¨åœ°é¢ä¸Šå®‰è£…æ±½è½¦æš‚åœçš„â€œæ‰˜ç›˜â€ï¼Œæ±½è½¦åœå¥½åŽï¼Œæ‰˜ç›˜ä¼šä¸‹é™åˆ°åœ°åº•ï¼Œå°†è½¦å­åœ¨åœ°åº•éš§é“é—´å¿«é€Ÿè¿è¾“ï¼Œæœ€å¿«æ—¶é€Ÿç”šè‡³åˆ°è¾¾200åƒç±³ã€‚ [19]Boringå…¬å¸ç”±é©¬æ–¯å…‹åœ¨SpaceXçš„é•¿æœŸå‰¯æ‰‹æ–¯è’‚å¤«Â·æˆ´ç»´æ–¯ï¼ˆSteve Davisï¼‰æŽŒèˆµã€‚2017å¹´7æœˆï¼Œé©¬æ–¯å…‹åœ¨æŽ¨ç‰¹ä¸Šè¡¨ç¤ºï¼Œä»–å¾—åˆ°äº†â€œæ”¿åºœå£å¤´æ‰¹å‡†â€ï¼Œå…è®¸Boringå…¬å¸å¼€å§‹å»ºé€ è¶…çº§é«˜é“ï¼ˆHyperloopï¼‰ã€‚è¶…çº§é«˜é“æ˜¯é©¬æ–¯å…‹åŸºäºŽä¸Šä¸–çºª70å¹´ä»£çš„ä¸€é¡¹æè®®é‡æ–°æå‡ºçš„æ¦‚å¿µï¼Œè¦æ±‚è½½å…·ä»¥æ¯å°æ—¶çº¦700è‹±é‡Œçš„é€Ÿåº¦é€šè¿‡çœŸç©ºç®¡è¿é€ä¹˜å®¢ã€‚2017å¹´ç§‹å¤©ï¼Œé©¬é‡Œå…°å·žåŠ å¿«Boringé¡¹ç›®çš„å®¡æ‰¹ç¨‹åºï¼ŒäºŽ2017å¹´10æœˆå‘æ”¾äº†æœ‰æ¡ä»¶çš„è®¸å¯è¯ï¼Œå‡ ä¸ªæœˆåŽåˆå‘æ”¾äº†çŽ¯å¢ƒè®¸å¯è¯ï¼Œä½†è¯¥é¡¹ç›®ç›´è‡³2023å¹´12æœˆï¼Œä»åªæœ‰å¯ä¾›æ¼”ç¤ºçš„2.4è‹±é‡Œï¼ˆçº¦åˆ3.8å…¬é‡Œï¼‰é•¿éš§é“ã€‚ [216-217]2023å¹´12æœˆï¼Œé©¬æ–¯å…‹è¶…çº§é«˜é“æ¢¦æƒ³ç ´ç¢Žï¼ŒHyperloop Oneï¼ˆå‰èº«ä¸ºVirgin Hyperloopï¼‰è¢«æ›æ­£åœ¨å‡ºå”®å…¶èµ„äº§ã€è§£é›‡å‰©ä½™å‘˜å·¥ï¼Œå¹¶å‡†å¤‡åœ¨2023å¹´åº•å‰å…³é—­ã€‚ [243]æŠ•èµ„äººå·¥æ™ºèƒ½DeepMind2010å¹´9æœˆï¼ŒDeepMindæˆç«‹ï¼Œé©¬æ–¯å…‹æ˜¯å…¶é¦–æ‰¹æŠ•èµ„äººã€‚2014å¹´ï¼ŒDeepMindè¢«è°·æ­Œä»¥6äº¿ç¾Žå…ƒçš„ä»·æ ¼æ”¶è´­ã€‚ | [93]ï¼Œé©¬æ–¯å…‹å…¥ä¸»æŽ¨ç‰¹åŽç»™è¿™å®¶å…¬å¸å¸¦æ¥å·¨å˜ï¼Œä¸€ç³»åˆ—çš„é™æœ¬å¢žæ•ˆæŽªæ–½è®©æŽ¨ç‰¹å‘˜å·¥éª¤å‡ä¸€åŠä»¥ä¸Šï¼Œä¹Ÿè®©æŽ¨ç‰¹é™·å…¥äº†ä¸€å®šç¨‹åº¦ä¸Šçš„å›°å¢ƒä¹‹ä¸­ã€‚ [97]2022å¹´12æœˆ20æ—¥æ™šï¼Œé©¬æ–¯å…‹åœ¨æŽ¨ç‰¹å‘æ–‡ç§°ï¼Œè‡ªå·±å°†è¾žåŽ»æŽ¨ç‰¹CEOä¸€èŒï¼Œä½†å‰ææ˜¯æ‰¾åˆ°â€œå‚»åˆ°å¯ä»¥æŽ¥ä»»è¿™é¡¹å·¥ä½œâ€çš„äººã€‚ [95-96]2023å¹´10æœˆ31æ—¥ï¼ŒæŽ¨ç‰¹å…¬å¸è‘£äº‹ä¼šè§£æ•£ï¼Œé©¬æ–¯å…‹æˆä¸ºæŽ¨ç‰¹çš„å”¯ä¸€è‘£äº‹ã€‚ [124]æ¶‰è¶³å½±è§†é™¤äº†ä¼—å¤šå•†ä¸šå…¬å¸å¤–ï¼Œé©¬æ–¯å…‹è¿˜åœ¨å½±è§†æ–¹é¢å±•çŽ°å‡ºå¤šå…ƒåŒ–çš„å‚ä¸Žå’Œå½±å“åŠ›ï¼Œä»–æ›¾ä¸ºä¸‰éƒ¨ç”µå½±å½“è¿‡åˆ¶ä½œäººï¼Œä¸Žå¥½èŽ±åžçš„å…³ç³»å¯†åˆ‡ï¼Œå½±æ˜Ÿä¹”æ²»Â·å…‹é²å°¼ã€å¯¼æ¼”å¡æ¢…éš†éƒ½æ˜¯ä»–çš„åº§ä¸Šå®¾ï¼Œåœ¨äº’è”ç½‘ç”µå½±èµ„æ–™åº“é‡Œæœç´¢ä»–çš„åå­—ï¼Œæœ‰é•¿é•¿ä¸€ä¸²ç»“æžœã€‚æ­¤å¤–ï¼Œä»–è¿˜åœ¨7éƒ¨ç”µå½±å’Œç”µè§†å‰§ä¸­å®¢ä¸²äº†ä»–è‡ªå·±ã€‚å½“ã€Šé’¢é“ä¾ ã€‹çš„å¯¼æ¼”ä¸ºäº†ä¸°å¯Œè§’è‰²æ‰¾åˆ°åŸƒéš†Â·é©¬æ–¯å…‹æ—¶ï¼Œä»–å¯¹å½“åˆ¶ä½œäººè¡¨è¾¾äº†å¼ºçƒˆå…´è¶£ï¼Œç”µå½±ä¸­ä¸€éƒ¨åˆ†é•œå¤´æ˜¯åœ¨SpaceXæ€»éƒ¨ç©ºæ—·çš„åŽ‚åŒºæ‹æ‘„ï¼Œæœ€åŽçš„å­—å¹•è¡¨é‡Œï¼ŒåŸƒéš†Â·é©¬æ–¯å…‹çš„åå­—åˆ—åœ¨â€œç‰¹åˆ«æ„Ÿè°¢â€ä¸€æ ã€‚åŸƒéš†Â·é©¬æ–¯å…‹åœ¨å½±è§†ä½œå“ä¸­å®¢ä¸²è‡ªå·±ç¤¾ä¼šæ´»åŠ¨æ’­æŠ¥ç¼–è¾‘å…¬ç›Šæ…ˆå–„é©¬æ–¯å…‹åŸºé‡‘ä¼šé©¬æ–¯å…‹åŸºé‡‘ä¼šï¼ˆMusk Foundationï¼‰æ˜¯é©¬æ–¯å…‹çš„ä¸»è¦æ…ˆå–„å·¥å…·ï¼Œæˆç«‹äºŽ2001å¹´ã€‚è¯¥åŸºé‡‘ä¼šç®€å•åˆä¸é€æ˜Žï¼Œä¸€åº¦æœ‰äººè´¨ç–‘é©¬æ–¯å…‹æ˜¯å¦åœ¨åšæ…ˆå–„ï¼ŒåŸºé‡‘ä¼šç½‘ç«™ä»¥çº¯æ–‡æœ¬æ ¼å¼æ”¾åœ¨Yahooé¡µé¢ä¸Šï¼Œæ²¡æœ‰é“¾æŽ¥ï¼Œæ²¡æœ‰å·¥ä½œäººå‘˜ä¿¡æ¯ï¼Œä¹Ÿæ²¡æœ‰è”ç³»è¡¨æ ¼ï¼Œåªæœ‰çŸ­çŸ­å‡ è¡Œå­—ï¼Œåˆ—å‡ºäº†åŸºé‡‘ä¼šçš„æåŠ©æ–¹å‘ï¼ŒåŒ…æ‹¬ï¼šå¯å†ç”Ÿèƒ½æºã€å¤ªç©ºæŽ¢ç´¢ã€å„¿ç§‘åŒ»å­¦ã€STEMç†å·¥ç§‘æ•™è‚²ä»¥åŠé€ ç¦äººç±»çš„äººå·¥æ™ºèƒ½ã€‚ç”±é©¬æ–¯å…‹çš„å¼Ÿå¼Ÿé‡‘å·´å°”Â·é©¬æ–¯å…‹ï¼ˆKimbal Muskï¼‰æ‹…ä»»åŸºé‡‘ä¼šå¸åº“ã€‚æ ¹æ®ç¾Žå›½å›½ç¨Žå±€ï¼ˆIRSï¼‰2001å¹´è‡³2017å¹´çš„æŠ¥å‘Šç»Ÿè®¡æ˜¾ç¤ºï¼Œé©¬æ–¯å…‹åŸºé‡‘ä¼šåœ¨15å¹´é—´ç´¯è®¡å‘160ä¸ªæ…ˆå–„æœºæž„æå‡ºäº†5400ä¸‡ç¾Žå…ƒï¼Œå…¶ä¸­æœ‰ä¸‰åˆ†ä¹‹ä¸€æ˜¯ç›´æŽ¥ææ¬¾ï¼Œææ¬¾é¢åº¦ä¸ºå‡ åƒç¾Žå…ƒä¸ç­‰ã€‚è¿™äº›æ…ˆå–„æœºæž„åŒ…æ‹¬çŽ¯ä¿ã€æ•™è‚²ã€åŒ»ç–—ä»¥åŠèˆªå¤©ç­‰ç­‰ã€‚é©¬æ–¯å…‹åŸºé‡‘ä¼šå¸¸ä½¿ç”¨DAFï¼ˆDonor Advised Fundï¼Œæèµ äººå»ºè®®åŸºé‡‘ï¼Œä¸€ç§å¯ä»¥è®©æèµ è€…ç®¡ç†æ…ˆå–„èµ„é‡‘å¦‚ä½•ä½¿ç”¨çš„åŸºé‡‘ç®¡ç†å…¬å¸ï¼‰è¿›è¡Œæ…ˆå–„æèµ ã€‚ [169-170]æçŒ®èª“è¨€2012å¹´ï¼Œé©¬æ–¯å…‹å“åº”ç›–èŒ¨å’Œå·´è²ç‰¹çš„å·å¬ï¼Œç­¾ç½²äº†â€œæèµ æ‰¿è¯ºâ€ï¼ˆThe Giving Pledgeï¼‰ï¼Œæ‰¿è¯ºåœ¨æœ‰ç”Ÿä¹‹å¹´å°†è‡ªå·±è‡³å°‘ä¸€åŠçš„èµ„äº§æç»™æ…ˆå–„æœºæž„ã€‚ç­¾ç½²äººå¯ä»¥è‡ªç”±é€‰æ‹©è‡ªå·±çš„æ…ˆå–„æèµ å¯¹è±¡ï¼Œæ—¢å¯ä»¥æ˜¯åŒ»å­¦ç ”ç©¶é¡¹ç›®ï¼Œä¹Ÿå¯ä»¥æ˜¯éžæ´²æ‰¶è´«é¡¹ç›®ï¼Œä¹Ÿå¯ä»¥æ˜¯ç¤¾ä¼šå…¬ç›Šæ´»åŠ¨ï¼Œæˆ–è€…æ˜¯æ•™è‚²å¹³ç­‰é¡¹ç›®ã€‚ä½†ä»–æ˜¯å°‘æ•°å‡ ä¸ªä¸åœ¨è¯¥é¡¹ç›®ç½‘ç«™ä¸Šå…¬å¼€å…¶æ‰¿è¯ºä¹¦çš„ç­¾ç½²è€…ä¹‹ä¸€ã€‚ [169-170]ç¤¾äº¤åª’ä½“å‘å¥–é©¬æ–¯å…‹å®šæœŸåœ¨æŽ¨ç‰¹ä¸Šï¼Œå‘é‚£äº›å‘¼åä»–å‚ä¸Žæ…ˆå–„çš„ç‰¹æ–¯æ‹‰ç²‰ä¸é€éœ²ä»–ä¸Žæ…ˆå–„ç›¸å…³çš„æƒ³æ³•ã€‚æœ‰æ—¶å€™ï¼Œè¿˜ä¼šæ‰¿è¯ºå°†è‡ªå·±åŸºé‡‘ä¼šçš„é’±å¥–åŠ±ç»™é‚£äº›åœ¨æŽ¨ç‰¹ä¸Šå‘ä»–å‘é—®çš„ç²‰ä¸ã€‚ [170]æ”¯æŒOpenAI2015å¹´ï¼Œéžå¸¸å…³æ³¨äººå·¥æ™ºèƒ½æŠ€æœ¯å‰æ™¯çš„é©¬æ–¯å…‹å’Œå‡ ä½å¯Œè±ªä¸€é“æ‰¿è¯ºæèµ 10äº¿ç¾Žå…ƒåˆ›å»ºOpenAIäººå·¥æ™ºèƒ½ç ”ç©¶å…¬å¸ï¼Œä»¥ä¾¿ä»¥â€œæœ€æœ‰å¯èƒ½é€ ç¦äººç±»çš„æ–¹å¼â€ç ”ç©¶å®‰å…¨çš„äººå·¥æ™ºèƒ½æŠ€æœ¯ã€‚å…¶ä¸­ï¼Œé©¬æ–¯å…‹æèµ äº†1000ä¸‡ç¾Žå…ƒã€‚ [169-170]å¤§é¢æèµ 2021å¹´11æœˆï¼Œé©¬æ–¯å…‹æå‡º504ä¸‡è‚¡ç‰¹æ–¯æ‹‰è‚¡ç¥¨ç”¨äºŽæ…ˆå–„ã€‚æŒ‰ç…§å½“æ—¶è‚¡ä»·ï¼Œè¿™éƒ¨åˆ†è‚¡ç¥¨ä»·å€¼è¶…è¿‡57.4äº¿ç¾Žå…ƒã€‚ä½†é©¬æ–¯å…‹æ²¡æœ‰é€éœ²è¿™ç¬”ææ¬¾çš„åŽ»å‘ï¼Œä¹Ÿæ²¡æœ‰å›žåº”åª’ä½“çš„è´¨è¯¢ã€‚ [169]æ•™è‚²æèµ 2020å¹´ï¼Œé©¬æ–¯å…‹å‘æ´›æ‰çŸ¶çš„å‡ æ‰€ç§ç«‹å­¦æ ¡è¿›è¡Œäº†ææ¬¾ï¼ŒåŒ…æ‹¬åå­—è·¯è‰ºæœ¯ä¸Žç§‘å­¦å­¦æ ¡ï¼ˆCrossroads School for Arts and Sciencesï¼‰å’Œè¿Žé£Žå­¦æ ¡ï¼ˆThe Windward Schoolï¼‰ã€‚ä»–çš„åŸºé‡‘ä¼šä¸ºåœ£å¿ƒå¤§å­¦ï¼ˆSacred Heart Universityï¼‰çš„ä¸€é¡¹æ–°å† ç—…æ¯’æŠ—ä½“ç ”ç©¶æ‹¨æ¬¾5ä¸‡ç¾Žå…ƒã€‚å¦å¤–ï¼Œé©¬æ–¯å…‹å‘Ad Astra Schoolæèµ 6ä¸‡ç¾Žå…ƒï¼Œè¿™æ˜¯ä»–äºŽ2014å¹´åœ¨SpaceXæ´›æ‰çŸ¶æ ¡åŒºä¸Žä»–äººåˆä½œåˆ›åŠžçš„ä¸€æ‰€å®žéªŒæ€§ç§ç«‹å­¦æ ¡ï¼Œå…¶å­å¥³å’Œä¸€äº›SpaceXå‘˜å·¥çš„å­å¥³éƒ½åœ¨è¿™æ‰€å­¦æ ¡é‡Œå°±è¯»ã€‚ [171]2022å¹´10æœˆï¼Œé©¬æ–¯å…‹æ——ä¸‹åŸºé‡‘ä¼šæäº¤äº†åœ¨å¾—å…‹è¨æ–¯å·žå¥¥æ–¯æ±€åˆ›åŠžä¸€æ‰€å¤§å­¦çš„ç”³è¯·ï¼Œå¹¶äºŽ2023å¹´3æœˆèŽ·å¾—æ‰¹å‡†ã€‚æ ¹æ®ç”³è¯·æ–‡ä»¶ï¼Œè¯¥åŸºé‡‘ä¼šä¼šåˆ©ç”¨é©¬æ–¯å…‹æèµ çš„çº¦1äº¿ç¾Žå…ƒèµ„é‡‘ä½œä¸ºç§å­èµ„é‡‘ï¼Œå…ˆåˆ›åŠžä¸€æ‰€ä»¥ç§‘å­¦ã€æŠ€æœ¯ã€å·¥ç¨‹å’Œæ•°å­¦ä¸ºé‡ç‚¹çš„å°å­¦å’Œä¸­å­¦ã€‚å­¦æ ¡ä¸€æ—¦å¼€å§‹è¿è¥ï¼ŒåŸºé‡‘ä¼šâ€œè®¡åˆ’æœ€ç»ˆæ‰©å¤§ä¸šåŠ¡ï¼Œåˆ›å»ºä¸€æ‰€è‡´åŠ›äºŽæœ€é«˜æ°´å¹³æ•™è‚²çš„å¤§å­¦â€ã€‚è¯¥å¤§å­¦å°†è˜è¯·â€œç»éªŒä¸°å¯Œçš„æ•™å¸ˆâ€ï¼Œå¹¶ä»¥ä¼ ç»Ÿè¯¾ç¨‹ä¸ºç‰¹è‰²ï¼Œâ€œä»¥åŠåŒ…æ‹¬æ¨¡æ‹Ÿã€æ¡ˆä¾‹ç ”ç©¶ã€åˆ¶é€ /è®¾è®¡é¡¹ç›®å’Œå®žéªŒå®¤åœ¨å†…çš„å®žè·µå­¦ä¹ ä½“éªŒâ€ã€‚ [172]å…¶ä»–æèµ é©¬æ–¯å…‹è¡¨ç¤ºï¼Œä»–æ˜¯ç¾Žå›½å…¬æ°‘è‡ªç”±è”ç›Ÿçš„â€œé¡¶çº§æèµ è€…ä¹‹ä¸€â€ï¼Œä½†ä»–å¹¶æ²¡æœ‰é€éœ²å…·ä½“çš„æèµ æ•°é¢ã€‚é©¬æ–¯å…‹ä¹Ÿä»Žæœªç™»ä¸Šã€Šç¦å¸ƒæ–¯ã€‹çš„é¡¶çº§æ…ˆå–„å®¶æŽ’è¡Œæ¦œã€‚ä¸‹è¡¨åˆ—å‡ºä»–ä¸€äº›ä¸»è¦çš„æèµ é¡¹ç›®ã€‚ [170-171]é©¬æ–¯å…‹çš„æèµ é¡¹ç›®ï¼ˆéƒ¨åˆ†ï¼‰æèµ é¡¹ç›®&æœºæž„æèµ é‡‘é¢ç”Ÿå‘½æœªæ¥ç ”ç©¶æ‰€ï¼ˆFuture of Life Instituteï¼‰ï¼Œä¸»è¦ç ”ç©¶äººå·¥æ™ºèƒ½å®‰å…¨è‡³å°‘1000ä¸‡ç¾Žå…ƒä¸€ä¸ªä¸“æ³¨äºŽä¿ƒè¿›å…¨çƒæ‰«ç›²çš„å¥–é¡¹1000ä¸‡ç¾Žå…ƒçŽ¯å¢ƒä¿æŠ¤ç»„ç»‡å¡žæ‹‰ä¿±ä¹éƒ¨ï¼ˆSierra
----------------------

Query: SpaceXç ”åˆ¶é¾™é£žèˆ¹2å·çš„æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™
Answer:
# ç¬¬äºŒä¸ªç¤ºä¾‹çš„ç»“æžœ
SpaceXä»Ž2014å¹´å¼€å§‹ç ”å‘é¾™é£žèˆ¹2å·ã€‚
"""

config["llm"]["config"]["stream"]=True
app = App.from_config(config=config)
app.add("https://baike.baidu.com/item/%E5%9F%83%E9%9A%86%C2%B7%E9%A9%AC%E6%96%AF%E5%85%8B/3776526?fr=ge_ala")
"""
>>> result = app.query("é©¬æ–¯å…‹åœ¨2001å¹´åˆåšäº†ä»€ä¹ˆ")
>>> for item in result:
>>>     print(item)
"""
```
</CodeGroup>
<br/ >

<Snippet file="missing-llm-tip.mdx" />
