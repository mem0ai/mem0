---
title: Add Memory
description: Add memory into the Mem0 platform by storing user-assistant interactions and facts for later retrieval.
icon: "plus"
iconType: "solid"
---

# How Mem0 Adds Memory

Adding memory is how Mem0 captures useful details from a conversation so your agents can reuse them later. Think of it as saving the important sentences from a chat transcript into a structured notebook your agent can search.

<Info>
  **Why it matters**
  - Preserves user preferences, goals, and feedback across sessions.
  - Powers personalization and decision-making in downstream conversations.
  - Keeps context consistent between managed Platform and OSS deployments.
</Info>

## Key terms

- **Messages** – The ordered list of user/assistant turns you send to `add`.
- **Infer** – Controls whether Mem0 extracts structured memories (`infer=True`, default) or stores raw messages.
- **Metadata** – Optional filters (e.g., `{"category": "movie_recommendations"}`) that improve retrieval later.
- **User / Session identifiers** – `user_id`, `session_id`, or `run_id` that scope the memory for future searches.

## How does it work?

Mem0 offers two flows:

- **Mem0 Platform** – Fully managed API with dashboard, scaling, and graph features.
- **Mem0 Open Source** – Local SDK that you run in your own environment.

Both flows take the same payload and pass it through the same pipeline.

<Frame caption="Architecture diagram illustrating the process of adding memories.">
  <img src="../../images/add_architecture.png" />
</Frame>

<Steps>
<Step title="Information extraction">
Mem0 sends the messages through an LLM that pulls out key facts, decisions, or preferences to remember.
</Step>
<Step title="Conflict resolution">
Existing memories are checked for duplicates or contradictions so the latest truth wins.
</Step>
<Step title="Storage">
The resulting memories land in managed vector storage (and optional graph storage) so future searches return them quickly.
</Step>
</Steps>

<Warning>
Duplicate protection only runs during that conflict-resolution step when you let Mem0 infer memories (`infer=True`, the default). If you switch to `infer=False`, Mem0 stores your payload exactly as provided, so duplicates will land. Mixing both modes for the same fact will save it twice.
</Warning>

You trigger this pipeline with a single `add` call—no manual orchestration needed.

## Add with Mem0 Platform

<CodeGroup>
```python Python
from mem0 import MemoryClient

client = MemoryClient(api_key="your-api-key")

messages = [
    {"role": "user", "content": "I'm planning a trip to Tokyo next month."},
    {"role": "assistant", "content": "Great! I’ll remember that for future suggestions."}
]

client.add(
    messages=messages,
    user_id="alice",
)
```

```javascript JavaScript
import { MemoryClient } from "mem0ai";

const client = new MemoryClient({apiKey: "your-api-key"});

const messages = [
  { role: "user", content: "I'm planning a trip to Tokyo next month." },
  { role: "assistant", content: "Great! I’ll remember that for future suggestions." }
];

await client.add(messages, {
  user_id: "alice",
  version: "v2",
});
```
</CodeGroup>

<Info icon="check">
  Expect a `memory_id` (or list of IDs) in the response. Check the Mem0 dashboard to confirm the new entry under the correct user.
</Info>

## Add with Mem0 Open Source

<CodeGroup>
```python Python
import os
from mem0 import Memory

os.environ["OPENAI_API_KEY"] = "your-api-key"

m = Memory()

messages = [
    {"role": "user", "content": "I'm planning to watch a movie tonight. Any recommendations?"},
    {"role": "assistant", "content": "How about thriller movies? They can be quite engaging."},
    {"role": "user", "content": "I'm not a big fan of thriller movies but I love sci-fi movies."},
    {"role": "assistant", "content": "Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future."}
]

# Store inferred memories (default behavior)
result = m.add(messages, user_id="alice", metadata={"category": "movie_recommendations"})

# Optionally store raw messages without inference
result = m.add(messages, user_id="alice", metadata={"category": "movie_recommendations"}, infer=False)
```

```javascript JavaScript
import { Memory } from 'mem0ai/oss';

const memory = new Memory();

const messages = [
  {
    role: "user",
    content: "I like to drink coffee in the morning and go for a walk"
  }
];

const result = memory.add(messages, {
  userId: "alice",
  metadata: { category: "preferences" }
});
```
</CodeGroup>

<Tip>
  Use `infer=False` only when you need to store raw transcripts. Most workflows benefit from Mem0 extracting structured memories automatically.
</Tip>

<Warning>
If you do choose `infer=False`, keep it consistent. Raw inserts skip conflict resolution, so a later `infer=True` call with the same content will create a second memory instead of updating the first.
</Warning>

## When Should You Add Memory?

Add memory whenever your agent learns something useful:

- A new user preference is shared
- A decision or suggestion is made
- A goal or task is completed
- A new entity is introduced
- A user gives feedback or clarification

<Callout type="tip" icon="plug">
  **MCP Alternative**: With <Link href="/platform/mem0-mcp">Mem0 MCP</Link>, AI agents can add memories automatically based on context.
</Callout>

Storing this context allows the agent to reason better in future interactions.


### More Details

For full list of supported fields, required formats, and advanced options, see the
[Add Memory API Reference](/api-reference/memory/add-memories).

## Managed vs OSS differences

| Capability | Mem0 Platform | Mem0 OSS |
| --- | --- | --- |
| Conflict resolution | Automatic with dashboard visibility | SDK handles merges locally; you control storage |
| Graph writes | Toggle per request (`enable_graph=True`) | Requires configuring a graph provider |
| Rate limits | Managed quotas per workspace | Limited by your hardware and provider APIs |
| Dashboard visibility | Yes — inspect memories visually | Inspect via CLI, logs, or custom UI |

## Put it into practice

- Review the <Link href="/platform/advanced-memory-operations">Advanced Memory Operations</Link> guide to layer metadata, rerankers, and graph toggles.
- Explore the <Link href="/api-reference/memory/add-memories">Add Memories API reference</Link> for every request/response field.

## See it live

- <Link href="/cookbooks/operations/support-inbox">Support Inbox with Mem0</Link> shows add + search powering a support flow.
- <Link href="/cookbooks/companions/ai-tutor">AI Tutor with Mem0</Link> uses add to personalize lesson plans.

{/* DEBUG: verify CTA targets */}

<CardGroup cols={2}>
  <Card
    title="Explore Search Concepts"
    description="See how stored memories feed retrieval in the Search guide."
    icon="search"
    href="/core-concepts/memory-operations/search"
  />
  <Card
    title="Build a Support Agent"
    description="Follow the cookbook to apply add/search/update in production."
    icon="rocket"
    href="/cookbooks/operations/support-inbox"
  />
</CardGroup>
