{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b02n_zJ_hl3d"
   },
   "source": [
    "## Cookbook for using VectaraDB with Embedchain\n",
    "\n",
    "[Vectara](https://vectara.com/) is the trusted GenAI and semantic search platform that provides an easy-to-use API for document indexing and querying. \n",
    "\n",
    "Vectara provides an end-to-end managed service for Retrieval Augmented Generation or [RAG](https://vectara.com/grounded-generation/), which includes:\n",
    "\n",
    "1. A way to extract text from document files and chunk them into sentences.\n",
    "\n",
    "2. The state-of-the-art [Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/) embeddings model. Each text chunk is encoded into a vector embedding using Boomerang, and stored in the Vectara internal knowledge (vector+text) store. Thus, when using Vectara with EmbedChain you do not need to call a separate embedder model - this happens automatically within the Vectara backend.\n",
    "\n",
    "3. A query service that automatically encodes the query into embedding, and retrieves the most relevant text segments (including support for [Hybrid Search](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching) and [MMR](https://vectara.com/get-diverse-results-and-comprehensive-summaries-with-vectaras-mmr-reranker/))\n",
    "\n",
    "4. An option to create [generative summary](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview), based on the retrieved documents, including citations.\n",
    "\n",
    "See the [Vectara API documentation](https://docs.vectara.com/docs/) for more information on how to use the API.\n",
    "\n",
    "This notebook demonstrates how to use Vectara with EmbedChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyJ6ui2vhtMY"
   },
   "source": [
    "### Step-1: Install embedchain package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-NbXjAdlh0vJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/ofer/dev/embedchain\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (4.12.2)\n",
      "Requirement already satisfied: chromadb<0.5.0,>=0.4.17 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (0.4.22)\n",
      "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (0.1.43)\n",
      "Requirement already satisfied: langchain<0.0.337,>=0.0.336 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (0.0.336)\n",
      "Requirement already satisfied: openai>=1.1.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (1.6.1)\n",
      "Requirement already satisfied: posthog<4.0.0,>=3.0.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (3.3.1)\n",
      "Requirement already satisfied: pypdf<4.0.0,>=3.11.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (3.16.1)\n",
      "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (0.3.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (1.0.0)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (13.7.0)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (0.7.5)\n",
      "Requirement already satisfied: tiktoken<0.5.0,>=0.4.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from embedchain==0.1.64) (0.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain==0.1.64) (2.4)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.0.3)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (2.5.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.104.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (4.8.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.15.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.41b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.20.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.15.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (6.0.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.58.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (29.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (4.1.0)\n",
      "Requirement already satisfied: cachetools in /Users/ofer/miniconda3/lib/python3.10/site-packages (from gptcache<0.2.0,>=0.1.43->embedchain==0.1.64) (5.3.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (3.9.1)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (0.0.79)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from openai>=1.1.1->embedchain==0.1.64) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from openai>=1.1.1->embedchain==0.1.64) (0.24.1)\n",
      "Requirement already satisfied: sniffio in /Users/ofer/miniconda3/lib/python3.10/site-packages (from openai>=1.1.1->embedchain==0.1.64) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from posthog<4.0.0,>=3.0.2->embedchain==0.1.64) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from posthog<4.0.0,>=3.0.2->embedchain==0.1.64) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from posthog<4.0.0,>=3.0.2->embedchain==0.1.64) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from posthog<4.0.0,>=3.0.2->embedchain==0.1.64) (2.8.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->embedchain==0.1.64) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->embedchain==0.1.64) (2.14.0)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from schema<0.8.0,>=0.7.5->embedchain==0.1.64) (21.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from tiktoken<0.5.0,>=0.4.0->embedchain==0.1.64) (2023.3.23)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from anyio<4.0->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /Users/ofer/miniconda3/lib/python3.10/site-packages (from anyio<4.0->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (1.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging>=19.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/ofer/miniconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.27.0)\n",
      "Requirement already satisfied: certifi in /Users/ofer/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.1.1->embedchain==0.1.64) (2023.11.17)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.1.1->embedchain==0.1.64) (0.16.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (2.3)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (2.16.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.5.1)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/ofer/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.26.18)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain==0.1.64) (0.1.2)\n",
      "Requirement already satisfied: coloredlogs in /Users/ofer/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/ofer/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /Users/ofer/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.20.3)\n",
      "Requirement already satisfied: sympy in /Users/ofer/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.11.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (6.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.60.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.20.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.20.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.41b0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.41b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.41b0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.41b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.41b0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.41b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.41b0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.41b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.41b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (67.7.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.41b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.14.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.41b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.7.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.2.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.19.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.5.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (10.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (4.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /Users/ofer/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (2023.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (3.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.0.337,>=0.0.336->embedchain==0.1.64) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ofer/miniconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.17->embedchain==0.1.64) (0.4.8)\n",
      "Building wheels for collected packages: embedchain\n",
      "  Building editable for embedchain (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for embedchain: filename=embedchain-0.1.64-py3-none-any.whl size=9350 sha256=ab9a9d64c2241676cfe5f43f8a63540d17b3d2d451bb6b090ca0f129c28dc331\n",
      "  Stored in directory: /private/var/folders/48/8_815vxj0vl2z5_28gys249r0000gn/T/pip-ephem-wheel-cache-5fzfn0i5/wheels/c1/10/22/d1bfbf20a6f1021e5a5c8f177f263d6d6ba4ea62066fbf8671\n",
      "Successfully built embedchain\n",
      "Installing collected packages: embedchain\n",
      "  Attempting uninstall: embedchain\n",
      "    Found existing installation: embedchain 0.1.64\n",
      "    Uninstalling embedchain-0.1.64:\n",
      "      Successfully uninstalled embedchain-0.1.64\n",
      "Successfully installed embedchain-0.1.64\n"
     ]
    }
   ],
   "source": [
    "!pip install embedchain[vectara]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGnpSYAAh2bQ"
   },
   "source": [
    "### Step-2: Set environment variables needed for Vectara\n",
    "\n",
    "You will need a Vectara account to use Vectara with EmbedChain. To get started, use the following steps:\n",
    "\n",
    "1. [Sign up](https://vectara.com/integrations/embedchain) for a Vectara account if you don't already have one. Once you have completed your sign up you will have a Vectara customer ID. You can find your customer ID by clicking on your name, on the top-right of the Vectara console window.\n",
    "\n",
    "2. By default you do not have to create a corpus, the EmbedChain integration with Vectara will create one for you (see \"collection-name\" in the configuration). If you want to pre-create that corpus, you can use the **\"Create Corpus\"** button. \n",
    "\n",
    "3. You will need to use Vectara's [OAUTH authentication](https://docs.vectara.com/docs/learn/authentication/oauth-2), and define the following environment variables:\n",
    "* `VECTARA_CUSTOMER_ID`\n",
    "* `VECTARA_OAUTH_CLIENT_ID`\n",
    "* `VECTARA_OAUTH_SECRET`\n",
    "\n",
    "If you are using Vectara as purely a retrieval engine (without summarization) then you would also need an OpenAI API key for the summarization\n",
    "\n",
    "* `OPENAI_API_KEY`\n",
    "\n",
    "You can have those environment variables set in the OS environment, or set these variables using os.environ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0fBdQ9GAiRvK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
    "os.environ[\"VECTARA_CUSTOMER_ID\"] = \"xxx\"\n",
    "os.environ[\"VECTARA_OAUTH_CLIENT_ID\"] = \"xxx\"\n",
    "os.environ[\"VECTARA_OAUTH_SECRET\"] = \"xxx\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGt6uPLIi1CS"
   },
   "source": [
    "### Step-3 Create embedchain app and define your config\n",
    "\n",
    "Since Vectara provides a GenAI platform (we call it RAG-in-a-box) you do not need an embedding provider as this is done inside the platform. So you can just use the FakeEmbedder instead.\n",
    "Furthermore, Vectara does its own chunking internally, so we configure the chunking to be a no-op (chunk size is 1M tokens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedchain import App\n",
    "\n",
    "ec_config = {\n",
    "    \"app\": {\n",
    "        \"config\": {\n",
    "            \"id\": \"vectara-docs\",\n",
    "        }\n",
    "    },\n",
    "    \"vectordb\": {\n",
    "        \"provider\": \"vectara\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"vectara-demo\",\n",
    "        }\n",
    "    },\n",
    "    \"chunker\": {\n",
    "        \"chunk_size\": 1000000,\n",
    "        \"chunk_overlap\": 0\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"fake\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as usual, we start by creating the EmbedChain app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Amzxk3m-i3tD"
   },
   "outputs": [],
   "source": [
    "app = App.from_config(config=ec_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNXv4yZwi7ef"
   },
   "source": [
    "### Step-4: Add data sources to your app\n",
    "\n",
    "For our example we will add the full content of Vectara's documentation site (choosing the \"docs_site\" data type).\n",
    "\n",
    "Note that specifying the `app.config.id` in the configuration above creates a unique APP_ID, ensuring that data already indexed will not be re-indexed in Vectara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Sn_0rx9QjIY9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 new documents to Vectara (out of 42 submitted to indexing)...\n",
      "Successfully saved https://docs.vectara.com/ (DataType.DOCS_SITE). New chunks count: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d1f20d25579de0cf550ce26446eaeaaa'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.add(\"https://docs.vectara.com/\", data_type=\"docs_site\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7W6fDeAjMAP"
   },
   "source": [
    "### Step-5: Let's ask some questions using Vectara as a vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cvIK7dWRjN_f"
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is Vectara?\",\n",
    "    \"How do I index documents in Vectara?\",\n",
    "    \"what is hybrid search and how does it work in Vectara?\",\n",
    "    \"What is RAG?\",\n",
    "    \"How does MMR work?\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for q in questions:\n",
    "    answer = app.query(q)\n",
    "    data.append([q, answer])\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7cdd_row0_col0, #T_f7cdd_row0_col1, #T_f7cdd_row1_col0, #T_f7cdd_row1_col1, #T_f7cdd_row2_col0, #T_f7cdd_row2_col1, #T_f7cdd_row3_col0, #T_f7cdd_row3_col1, #T_f7cdd_row4_col0, #T_f7cdd_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7cdd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f7cdd_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_f7cdd_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7cdd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f7cdd_row0_col0\" class=\"data row0 col0\" >What is Vectara?</td>\n",
       "      <td id=\"T_f7cdd_row0_col1\" class=\"data row0 col1\" >Vectara is a platform that allows users to create and manage corpora, which are collections of documents. It provides various APIs for indexing and segmenting documents, as well as features for deleting and uploading files. Vectara is flexible in terms of the types of documents it can handle, ranging from short tweets to lengthy texts like the Bible. Indexing data into Vectara is typically a fast process, taking only a few seconds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7cdd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f7cdd_row1_col0\" class=\"data row1 col0\" >How do I index documents in Vectara?</td>\n",
       "      <td id=\"T_f7cdd_row1_col1\" class=\"data row1 col1\" >To index documents in Vectara, you can use either the Standard Indexing API or the File Upload API. The Standard Indexing method is recommended for indexing a set of semi-structured documents or content into a corpus. Vectara will index and chunk the documents for you. The File Upload method allows you to upload and index files into a corpus using an HTTP endpoint. The first step in using Vectara is to index a set of related documents or content into a corpus. Indexing a document makes the data available for search and retrieval more efficiently.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7cdd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f7cdd_row2_col0\" class=\"data row2 col0\" >what is hybrid search and how does it work in Vectara?</td>\n",
       "      <td id=\"T_f7cdd_row2_col1\" class=\"data row2 col1\" >Hybrid search in Vectara is a retrieval model that combines traditional, keyword-based search with semantic search. It blends partial, exact, and Boolean text matching with neural models to provide a powerful and flexible approach to text retrieval. \n",
       "\n",
       "In Vectara, hybrid search allows you to include exact keyword matches for search terms that were not present in Vectara's training data, such as product SKUs. It also enables you to disable neural retrieval entirely and instead use exact term matching. Additionally, you can incorporate typical keyword modifiers like a NOT function, exact phrase matching, and wildcard prefixes of terms.\n",
       "\n",
       "To enable hybrid search in Vectara, you need to specify a value called \"lambda\" at query time, specifically under the corpusKey. The lambda value can range from 0 to 1 (inclusive).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7cdd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f7cdd_row3_col0\" class=\"data row3 col0\" >What is RAG?</td>\n",
       "      <td id=\"T_f7cdd_row3_col1\" class=\"data row3 col1\" >RAG stands for Retrieval Augmented Generation. It is a technology used by Vectara to ensure that generated content is both verifiable and anchored to the data provided. RAG minimizes the occurrence of hallucinations, which are inaccurate or misleading information commonly found in generative AI systems. It summarizes search results that answer complex queries directly while providing citations that ground these search results in facts from the data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7cdd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f7cdd_row4_col0\" class=\"data row4 col0\" >How does MMR work?</td>\n",
       "      <td id=\"T_f7cdd_row4_col1\" class=\"data row4 col1\" >I don't have enough information to answer the query.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16c020490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with the citations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vectara is a platform that allows users to create and manage corpora, which are collections of documents. It provides various APIs for indexing and segmenting documents, as well as features for deleting and uploading files. Vectara is flexible in terms of the types of documents it can handle, ranging from short tweets to lengthy texts like the Bible. Indexing data into Vectara is typically a fast process, taking only a few seconds.',\n",
       " [(\"Why certain birds are allowed for the most random reason? We have part of a\\nunique employee handbook ready for you to upload into a Vectara corpus,\\nand we'll guide you through the ingestion and question answering process step by step. <%START%>Step 1. Create a Vectara account \\u200b To get started with Vectara , go to https://console.vectara.com/signup or\\nclick Get Started Free at vectara.com.<%END%> After you make an account, you can\\ncreate your first corpus and upload your first document! Step 2. Create your first corpus \\u200b Before you can ask the data about bringing your velociraptor to the\\noffice, you first need to create a corpus.\",\n",
       "   {'lang': 'eng',\n",
       "    'offset': '486',\n",
       "    'len': '147',\n",
       "    'score': 0.4966065,\n",
       "    'url': 'https://docs.vectara.com/docs/quickstart',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('We recommend this option if you have not written your own extraction logic\\nalready. Standard Indexing API If you have structured documents that you want Vectara to index and segment\\ninto chunks for you, use the standard indexing API. <%START%>In Vectara, a document is very flexible in what it can represent.<%END%> It can be as short as a tweet or\\nas long as the 1600 page Bible. The document object typically includes\\nunique identifiers like title , description , and metadata that you can\\nleverage.',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '1299',\n",
       "    'len': '65',\n",
       "    'score': 0.2481998,\n",
       "    'url': 'https://docs.vectara.com/docs/learn/select-ideal-indexing-api',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  (\"Indexing operations, such as creating and deleting documents üìÑÔ∏è Delete Delete documents from a corpus. üìÑÔ∏è Index This is the 'standard' Indexing API for indexing semi-structured, text-heavy 'documents.' <%START%>Indexing data into Vectara is typically very fast: within a few seconds.<%END%> üìÑÔ∏è CoreIndex This API is intended to be used by experts. It gives you fine-grained control over chunking üìÑÔ∏è FileUpload The File Upload API can be used to index binary files like PDFs, Word Documents, and similar.\",\n",
       "   {'lang': 'eng',\n",
       "    'offset': '205',\n",
       "    'len': '72',\n",
       "    'score': 0.18344173,\n",
       "    'url': 'https://docs.vectara.com/docs/rest-api/index-service',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.query(\"What is Vectara?\", citations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-6: Now use Vectara's full end-to-end RAG capabilities:\n",
    "Note that in this case we use the `VectaraApp` class which makes sure the LLM is called from the Vectara backend and you do not need to call OpenAI or another LLM for the summarization, instead this comes from the Vectara service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedchain.vectordb.vectara import VectaraApp\n",
    "app = VectaraApp.from_config(config=ec_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is Vectara?\",\n",
    "    \"How do I index documents in Vectara?\",\n",
    "    \"what is hybrid search and how does it work in Vectara?\",\n",
    "    \"What is RAG?\",\n",
    "    \"How does MMR work?\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for q in questions:\n",
    "    answer = app.query(q)\n",
    "    data.append([q, answer])\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e772_row0_col0, #T_0e772_row0_col1, #T_0e772_row1_col0, #T_0e772_row1_col1, #T_0e772_row2_col0, #T_0e772_row2_col1, #T_0e772_row3_col0, #T_0e772_row3_col1, #T_0e772_row4_col0, #T_0e772_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e772\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e772_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_0e772_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e772_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0e772_row0_col0\" class=\"data row0 col0\" >What is Vectara?</td>\n",
       "      <td id=\"T_0e772_row0_col1\" class=\"data row0 col1\" >Vectara is a platform designed for developers with an API-first approach. It offers a complete end-to-end solution for integrating generative AI search into applications. Vectara allows users to create a corpus, upload and index documents, and extract text and metadata from files such as PDFs and Word Documents. With Vectara, you can create an answer engine and benefit from its hybrid search core and superior language understanding capabilities. The platform provides easy ingestion, simple APIs, and fine-grained control over indexing and segmentation. It is a secure and developer-focused solution for integrating AI search functionality .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e772_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0e772_row1_col0\" class=\"data row1 col0\" >How do I index documents in Vectara?</td>\n",
       "      <td id=\"T_0e772_row1_col1\" class=\"data row1 col1\" >The Vectara platform offers different methods for indexing documents. The recommended approach is to use the Standard Indexing API, which is suitable for structured documents and allows Vectara to index and chunk the content efficiently. Another option is to utilize the File Upload API, which provides an HTTP endpoint to upload and index files into a corpus. Additionally, Vectara supports filter expressions to restrict searches to specific parts of the corpus based on metadata. To manage the ingested documents and check their status, you can use the ListDocuments API. Please note that the provided search results did not contain sufficient information to be summarized into a comprehensive answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e772_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0e772_row2_col0\" class=\"data row2 col0\" >what is hybrid search and how does it work in Vectara?</td>\n",
       "      <td id=\"T_0e772_row2_col1\" class=\"data row2 col1\" >Hybrid search in Vectara combines partial, exact, and Boolean text matching with neural models, blending traditional keyword-based search with semantic search. This approach allows for powerful and flexible text retrieval. Vectara deploys advanced zero-shot models and conversational search capabilities to understand and interpret user queries accurately. It offers a hybrid retrieval model that includes exact keyword matches, disabling neural retrieval, and incorporating keyword modifiers. Vectara's hybrid search can be enabled by specifying a value between 0 and 1 at query time. This approach ensures that Vectara provides precise and contextually accurate responses, making it an optimal choice for integrating generative AI search into applications .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e772_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0e772_row3_col0\" class=\"data row3 col0\" >What is RAG?</td>\n",
       "      <td id=\"T_0e772_row3_col1\" class=\"data row3 col1\" >Retrieval Augmented Generation (RAG) is a technique used by Vectara to ensure that generated content is verifiable and anchored to the provided data, reducing the occurrence of hallucinations in AI systems. RAG combines retrieval-based methods with generative models to answer complex queries directly and provide citations that ground the search results in factual data. By minimizing hallucinations, Vectara enhances trust in AI-powered decision making. This approach is language-agnostic, allowing users to search across multiple languages. RAG can be used to establish question-answer databases, providing authoritative answers to users. It addresses the problem of false information by focusing on facts and reducing inaccurate and misleading responses. Vectara offers an API Playground for developers to experiment with their REST APIs and understand the fundamentals of APIs. Vectara also provides demo applications that showcase the power of GenAI conversational search and RAG .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e772_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0e772_row4_col0\" class=\"data row4 col0\" >How does MMR work?</td>\n",
       "      <td id=\"T_0e772_row4_col1\" class=\"data row4 col1\" >The returned results did not contain sufficient information to be summarized into a useful answer for your query. Please try a different search or restate your query differently.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1667f6c80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with citations enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vectara is a platform that offers an API-first approach for developers to integrate generative AI search into their applications. It provides a hybrid search core and language understanding for ingestion and retrieval [4]. Vectara allows users to create a corpus, upload documents, and index them [2]. It supports various indexing operations, including creating, deleting, and indexing documents [3]. The platform is designed to be developer-focused, secure, and offers easy ingestion and simple APIs [4]. Additionally, Vectara provides a File Upload API for uploading and indexing files like PDFs and Word Documents [5]. Overall, Vectara aims to be an answer engine that enables efficient search and retrieval of information [4].',\n",
       " [(\"Why certain birds are allowed for the most random reason? We have part of a\\nunique employee handbook ready for you to upload into a Vectara corpus,\\nand we'll guide you through the ingestion and question answering process step by step. <%START%>Step 1. Create a Vectara account \\u200b To get started with Vectara , go to https://console.vectara.com/signup or\\nclick Get Started Free at vectara.com.<%END%> After you make an account, you can\\ncreate your first corpus and upload your first document! Step 2. Create your first corpus \\u200b Before you can ask the data about bringing your velociraptor to the\\noffice, you first need to create a corpus.\",\n",
       "   {'lang': 'eng',\n",
       "    'offset': '486',\n",
       "    'len': '147',\n",
       "    'score': 0.4966065,\n",
       "    'url': 'https://docs.vectara.com/docs/quickstart',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('We recommend this option if you have not written your own extraction logic\\nalready. Standard Indexing API If you have structured documents that you want Vectara to index and segment\\ninto chunks for you, use the standard indexing API. <%START%>In Vectara, a document is very flexible in what it can represent.<%END%> It can be as short as a tweet or\\nas long as the 1600 page Bible. The document object typically includes\\nunique identifiers like title , description , and metadata that you can\\nleverage.',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '1299',\n",
       "    'len': '65',\n",
       "    'score': 0.2481998,\n",
       "    'url': 'https://docs.vectara.com/docs/learn/select-ideal-indexing-api',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  (\"Indexing operations, such as creating and deleting documents üìÑÔ∏è Delete Delete documents from a corpus. üìÑÔ∏è Index This is the 'standard' Indexing API for indexing semi-structured, text-heavy 'documents.' <%START%>Indexing data into Vectara is typically very fast: within a few seconds.<%END%> üìÑÔ∏è CoreIndex This API is intended to be used by experts. It gives you fine-grained control over chunking üìÑÔ∏è FileUpload The File Upload API can be used to index binary files like PDFs, Word Documents, and similar.\",\n",
       "   {'lang': 'eng',\n",
       "    'offset': '205',\n",
       "    'len': '72',\n",
       "    'score': 0.18344173,\n",
       "    'url': 'https://docs.vectara.com/docs/rest-api/index-service',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('Vectara summarizes search results on complex queries while providing factual\\ncitations from your data. Vectara provides the best hybrid search\\ncore and superior language understanding for ingestion and retrieval. <%START%>Vectara can become your answer engine.<%END%> Developer-focused, API-first, Secure \\u200b Designed for developers with an API-first approach, Vectara is\\nthe optimal choice to integrate generative AI search into your\\napplications. This complete end-to-end platform provides easy ingestion and\\nsimple APIs.',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '1420',\n",
       "    'len': '38',\n",
       "    'score': 0.18123072,\n",
       "    'url': 'https://docs.vectara.com/docs/',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('You can also experiment with this REST endpoint in our interactive API Playground . File Upload API \\u200b The File Upload method exposes an\\nHTTP endpoint to upload and index files into a corpus. <%START%>We recommend this\\noption when you do not need to define additional user-supplied metadata beyond\\nwhat is extracted by the Vectara platform.<%END%> When you upload files like PDFs and\\nWord Documents, Vectara attempts to automatically extract the text and any metadata. If you want to attach metadata for optimizing searches made against your data,\\nyou can format your data as JSON .',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '950',\n",
       "    'len': '139',\n",
       "    'score': 0.1579486,\n",
       "    'url': 'https://docs.vectara.com/docs/learn/data-ingestion',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('These hallucinations\\nlead to inaccurate and misleading responses Vectara addresses\\nthis problem through Retrieval Augmented Generation (RAG) , meaning it grounds the search\\nresults in the uploaded data. By focusing on facts and reducing\\nhallucinations, Vectara enhances trust in AI-powered decision making. <%START%>Language Agnostic \\u200b Use Vectara to search across multiple languages, eliminating language\\nbarriers and enabling users to find what they need, regardless of the\\nlanguage they use.<%END%> This cross-language approach provides a seamless\\nsearch experience for users around the world. The best answer may be\\nwritten in German but a user asked the question in Spanish.',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '2985',\n",
       "    'len': '178',\n",
       "    'score': 0.15068102,\n",
       "    'url': 'https://docs.vectara.com/docs/',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('Vectara offers significant improvements over traditional searches by understanding the context and meaning of your data. This revolutionary technology enables Vectara to drive insights and provide more accurate responses to user queries, assisting decision-making processes. <%START%>User data remains secure because Vectara never trains on customer data.<%END%> Welcome to the Answer Engine \\u200b The Vectara team envisions a future where generative AI powers every\\napplication to deliver contextually accurate responses and give the right\\nanswers and actions. Vectara is built on a solid hybrid search core\\nto enable better generative outcomes.',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '585',\n",
       "    'len': '71',\n",
       "    'score': 0.14569515,\n",
       "    'url': 'https://docs.vectara.com/docs/',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('üîß Build API Requests: Create API requests within the console and copy-paste\\ninto your code. üí∞ Manage Billing Details: View account usage information and payment\\ndetails to ensure uninterrupted service. <%START%>üåê Vectara Platform Overview: Learn about the Vectara Platform and view interactive\\nparts of our documentation like the API Playground .<%END%> The Vectara Console Overview home page also provides helpful links to get you started\\nwith our plaltform:',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '929',\n",
       "    'len': '136',\n",
       "    'score': 0.14425495,\n",
       "    'url': 'https://docs.vectara.com/docs/console-ui/vectara-console-overview',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  ('User data remains secure because Vectara never trains on customer data. Welcome to the Answer Engine \\u200b The Vectara team envisions a future where generative AI powers every\\napplication to deliver contextually accurate responses and give the right\\nanswers and actions. <%START%>Vectara is built on a solid hybrid search core\\nto enable better generative outcomes.<%END%> Traditional search technologies focus\\non keywords, which limit their ability to understand complex queries. Vectara deploys advanced zero-shot models and conversational search capabilities to understand, interpret, and respond to user queries with remarkable\\nprecision.',\n",
       "   {'lang': 'eng',\n",
       "    'offset': '852',\n",
       "    'len': '84',\n",
       "    'score': 0.14389877,\n",
       "    'url': 'https://docs.vectara.com/docs/',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'}),\n",
       "  (\"epub files. Review supported file types for\\na full list. Select or drag and drop the pet policy document PDF into the corpus. <%START%>That's it! Vectara has just ingested this important document!<%END%> Step 4. Get answers from your uploaded content \\u200b Let's take a closer look at the employee handbook you just uploaded. Since Vectara has\\nnow ingested the data, you can ask all sorts of questions and receive\\nmeaningful and relevant results.\",\n",
       "   {'lang': 'eng',\n",
       "    'offset': '2526',\n",
       "    'len': '61',\n",
       "    'score': 0.13739622,\n",
       "    'url': 'https://docs.vectara.com/docs/quickstart',\n",
       "    'data_type': 'docs_site',\n",
       "    'doc_id': 'vectara-docs--420a93ae17ea6061af2c139e2503ddb3e848003c07ad3306c72238ef64967dd6',\n",
       "    'app_id': 'vectara-docs',\n",
       "    'hash': 'd1f20d25579de0cf550ce26446eaeaaa'})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.query(\"What is Vectara?\", citations=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
